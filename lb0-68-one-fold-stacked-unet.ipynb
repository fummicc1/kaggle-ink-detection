{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["for dicsussion, refer to https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/407972#2272189"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append('/kaggle/input/ink-00/my_lib')\n","sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\n","sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\n","sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","sys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models.pytorch-master')\n","sys.path.append('/kaggle/input/einops/einops-master')"]},{"cell_type":"code","execution_count":11,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-23T14:27:12.625278Z","iopub.status.busy":"2023-05-23T14:27:12.624772Z","iopub.status.idle":"2023-05-23T14:27:19.728486Z","shell.execute_reply":"2023-05-23T14:27:19.727509Z","shell.execute_reply.started":"2023-05-23T14:27:12.625239Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["import ok !!!\n"]}],"source":["import hashlib\n","import numpy as np\n","import pandas as pd\n","from dotdict import dotdict\n","\n","from collections import defaultdict\n","from glob import glob\n","import PIL.Image as Image\n","from timer import timer\n","Image.MAX_IMAGE_PIXELS = 10000000000  # Ignore PIL warnings about large images\n","\n","import cv2\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from einops import rearrange, reduce, repeat\n","import segmentation_models_pytorch as smp\n","from segmentation_models_pytorch.decoders.unet.decoder import UnetDecoder, DecoderBlock\n","from timm.models.resnet import resnet10t, resnet34d\n","\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","#matplotlib.use('TkAgg')\n","%matplotlib inline \n","  \n","print('import ok !!!')"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T14:27:19.731309Z","iopub.status.busy":"2023-05-23T14:27:19.730717Z","iopub.status.idle":"2023-05-23T14:27:19.741486Z","shell.execute_reply":"2023-05-23T14:27:19.740450Z","shell.execute_reply.started":"2023-05-23T14:27:19.731273Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CFG\n","\tmode : ['train']\n","\tcrop_fade : 56\n","\tcrop_size : 384\n","\tcrop_depth : 5\n","\tinfer_fragment_z : [28, 37]\n","\tis_tta : True\n","\tstride : 192\n"]}],"source":["class Config(object):\n","\tmode = [\n","\t\t'train', #\n","\t\t# 'test', 'skip_fake_test',\n","\t]\n","\tcrop_fade  = 56\n","\tcrop_size  = 384\n","\tcrop_depth = 5\n","\tinfer_fragment_z = [28, 37]\n","\n","CFG = Config()\n","CFG.is_tta = True #True\n","\n","\n","if 'train' in CFG.mode:\n","\tCFG.stride = CFG.crop_size//2\n","if 'test' in CFG.mode:\n","\tCFG.stride = CFG.crop_size//2\n","\n","\n","def cfg_to_text():\n","    d = Config.__dict__\n","    text = [f'\\t{k} : {v}' for k,v in d.items() if not (k.startswith('__') and k.endswith('__'))]\n","    d = CFG.__dict__\n","    text += [f'\\t{k} : {v}' for k,v in d.items() if not (k.startswith('__') and k.endswith('__'))]\n","    return 'CFG\\n'+'\\n'.join(text)\n","\n","print(cfg_to_text())"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T14:27:19.744030Z","iopub.status.busy":"2023-05-23T14:27:19.743332Z","iopub.status.idle":"2023-05-23T14:27:19.764990Z","shell.execute_reply":"2023-05-23T14:27:19.763996Z","shell.execute_reply.started":"2023-05-23T14:27:19.743998Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["data_dir /home/fummicc1/codes/Kaggle/kaggle-ink-detection/train\n","valid_id ['1']\n","data ok !!!\n"]}],"source":["## dataset ##\n","if 'train' in CFG.mode:\n","\tdata_dir = '/home/fummicc1/codes/Kaggle/kaggle-ink-detection/train'\n","\tvalid_id =[\n","\t    '1',#'2b',\n","\t]\n","\n","if 'test' in CFG.mode: \n","\tdata_dir = '/kaggle/input/vesuvius-challenge-ink-detection/test'\n","\tvalid_id = glob(f'{data_dir}/*')\n","\tvalid_id = sorted(valid_id)\n","\tvalid_id = [f.split('/')[-1] for f in valid_id]\n","    \n","\t# https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/410985\n","\ta_file = f'{data_dir}/a/mask.png'\n","\twith open(a_file,'rb') as f:\n","\t\thash_md5 = hashlib.md5(f.read()).hexdigest()\n","\tis_skip_test = hash_md5 == '0b0fffdc0e88be226673846a143bb3e0'\n","\tprint('is_skip_test:',is_skip_test)\n","\n","#---\n","print('data_dir', data_dir)\n","print('valid_id', valid_id)\n","\n","def do_binarise(m, threshold=0.5):\n","    m = m-m.min()\n","    m = m/(m.max()+1e-7)\n","    m = (m>threshold).astype(np.float32)\n","    return m\n","\n","def read_data(fragment_id, z0=CFG.infer_fragment_z[0], z1=CFG.infer_fragment_z[1]):\n","    volume = []\n","    start_timer = timer()\n","    for i in range(z0,z1):\n","        v = np.array(Image.open(f'{data_dir}/{fragment_id}/surface_volume/{i:02d}.tif'), dtype=np.uint16)\n","        v = (v >> 8).astype(np.uint8)\n","        #v = (v / 65535.0 * 255).astype(np.uint8)\n","        volume.append(v)\n","        print(f'\\r @ read_data(): volume{fragment_id}  {time_to_str(timer() - start_timer, \"sec\")}', end='', flush=True)\n","    #print('')\n","    volume = np.stack(volume, -1)\n","    height, width, depth = volume.shape\n","    #print(f'fragment_id={fragment_id} volume: {volume.shape}')\n","\n","    #---\n","    mask = cv2.imread(f'{data_dir}/{fragment_id}/mask.png',cv2.IMREAD_GRAYSCALE)\n","    mask = do_binarise(mask)\n","\n","    if 'train' in CFG.mode:\n","        ir    = cv2.imread(f'{data_dir}/{fragment_id}/ir.png',cv2.IMREAD_GRAYSCALE)\n","        label = cv2.imread(f'{data_dir}/{fragment_id}/inklabels.png',cv2.IMREAD_GRAYSCALE)\n","        ir    = ir/255\n","        label = do_binarise(label)\n","\n","    if 'test' in CFG.mode:\n","        ir = None\n","        label = None\n","\n","    d = dotdict(\n","        fragment_id = fragment_id,\n","        volume = volume,\n","        ir     = ir,\n","        label  = label,\n","        mask   = mask,\n","    )\n","    return d\n","\n","def read_data1(fragment_id):\n","\tif fragment_id=='2a':\n","\t\ty = 9456\n","\t\td = read_data('2') \n","\t\td = dotdict(\n","\t\t\tfragment_id='2a',\n","\t\t\tvolume  = d.volume[:y],\n","\t\t\tir      = d.ir[:y],\n","\t\t\tlabel   = d.label[:y],\n","\t\t\tmask    = d.mask[:y],\n","\t\t)\n","\telif  fragment_id=='2b':\n","\t\ty = 9456\n","\t\td = read_data('2') \n","\t\td = dotdict(\n","\t\t\tfragment_id='2b',\n","\t\t\tvolume  = d.volume[y:],\n","\t\t\tir      = d.ir[y:],\n","\t\t\tlabel   = d.label[y:],\n","\t\t\tmask    = d.mask[y:],\n","\t\t)\n","\telse:\n","\t\td = read_data(fragment_id)\n","\treturn d\n","\n","def run_check_data():\n","    d=read_data1(valid_id[0])#valid_id[0]\n","    print('')\n","    print('fragment_id:', d.fragment_id)\n","    print('volume:', d.volume.shape, d.volume.min(), d.volume.max())\n","    print('mask  :', d.mask.shape, d.mask.min(), d.mask.max())\n","    if 'train' in CFG.mode:\n","        print('ir    :', d.ir.shape, d.ir.min(), d.ir.max())\n","        print('label :', d.label.shape, d.label.min(), d.label.max())\n","\n","#run_check_data()\n","print('data ok !!!')"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T14:27:19.768197Z","iopub.status.busy":"2023-05-23T14:27:19.767528Z","iopub.status.idle":"2023-05-23T14:27:26.346770Z","shell.execute_reply":"2023-05-23T14:27:26.345867Z","shell.execute_reply.started":"2023-05-23T14:27:19.768163Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["batch\n","                          volume : torch.Size([3, 9, 384, 384]) \n","output\n","                             ink : torch.Size([3, 1, 384, 384]) \n","net ok !!!\n"]}],"source":["## model ##\n","class SmpUnetDecoder(nn.Module):\n","\tdef __init__(self,\n","\t         in_channel,\n","\t         skip_channel,\n","\t         out_channel,\n","\t    ):\n","\t\tsuper().__init__()\n","\t\tself.center = nn.Identity()\n","\n","\t\ti_channel = [in_channel,]+ out_channel[:-1]\n","\t\ts_channel = skip_channel\n","\t\to_channel = out_channel\n","\t\tblock = [\n","\t\t\tDecoderBlock(i, s, o, use_batchnorm=True, attention_type=None)\n","\t\t\tfor i, s, o in zip(i_channel, s_channel, o_channel)\n","\t\t]\n","\t\tself.block = nn.ModuleList(block)\n","\n","\tdef forward(self, feature, skip):\n","\t\td = self.center(feature)\n","\t\tdecode = []\n","\t\tfor i, block in enumerate(self.block):\n","\t\t\ts = skip[i]\n","\t\t\td = block(d, s)\n","\t\t\tdecode.append(d)\n","\n","\t\tlast  = d\n","\t\treturn last, decode\n","\n","class Net(nn.Module):\n","\tdef __init__(self,):\n","\t\tsuper().__init__()\n","\t\tself.output_type = ['inference', 'loss']\n","\n","\t\tconv_dim = 64\n","\t\tencoder1_dim  = [conv_dim, 64, 128, 256, 512, ]\n","\t\tdecoder1_dim  = [256, 128, 64, 64,]\n","\n","\t\tself.encoder1 = resnet34d(pretrained=False, in_chans=CFG.crop_depth)\n","\n","\t\tself.decoder1 = SmpUnetDecoder(\n","\t\t\tin_channel   = encoder1_dim[-1],\n","\t\t\tskip_channel = encoder1_dim[:-1][::-1],\n","\t\t\tout_channel  = decoder1_dim,\n","\t\t)\n","\t\t# -- pool attention weight\n","\t\tself.weight1 = nn.ModuleList([\n","\t\t\tnn.Sequential(\n","\t\t\t\tnn.Conv2d(dim, dim, kernel_size=3, padding=1),\n","\t\t\t\tnn.ReLU(inplace=True),\n","\t\t\t) for dim in encoder1_dim\n","\t\t])\n","\t\tself.logit1 = nn.Conv2d(decoder1_dim[-1],1,kernel_size=1)\n","\n","\t\t#--------------------------------\n","\t\t#\n","\t\tencoder2_dim  = [64, 128, 256, 512]#\n","\t\tdecoder2_dim  = [128, 64, 32, ]\n","\t\tself.encoder2 = resnet10t(pretrained=False, in_chans=decoder1_dim[-1])\n","\n","\t\tself.decoder2 = SmpUnetDecoder(\n","\t\t\tin_channel   = encoder2_dim[-1],\n","\t\t\tskip_channel = encoder2_dim[:-1][::-1],\n","\t\t\tout_channel  = decoder2_dim,\n","\t\t)\n","\t\tself.logit2 = nn.Conv2d(decoder2_dim[-1],1,kernel_size=1)\n","\n","\tdef forward(self, batch):\n","\t\tv = batch['volume']\n","\t\tB,C,H,W = v.shape\n","\t\tvv = [\n","\t\t\tv[:,i:i+CFG.crop_depth] for i in [0,2,4,]\n","\t\t]\n","\t\tK = len(vv)\n","\t\tx = torch.cat(vv,0)\n","\t\t#x = v\n","\n","\t\t#----------------------\n","\t\tencoder = []\n","\t\te = self.encoder1\n","\t\tx = e.conv1(x)\n","\t\tx = e.bn1(x)\n","\t\tx = e.act1(x);\n","\t\tencoder.append(x)\n","\t\tx = F.avg_pool2d(x, kernel_size=2, stride=2)\n","\t\tx = e.layer1(x);\n","\t\tencoder.append(x)\n","\t\tx = e.layer2(x);\n","\t\tencoder.append(x)\n","\t\tx = e.layer3(x);\n","\t\tencoder.append(x)\n","\t\tx = e.layer4(x);\n","\t\tencoder.append(x)\n","\t\t# print('encoder', [f.shape for f in encoder])\n","\n","\t\tfor i in range(len(encoder)):\n","\t\t\te = encoder[i]\n","\t\t\tf = self.weight1[i](e)\n","\t\t\t_, c, h, w = e.shape\n","\t\t\tf = rearrange(f, '(K B) c h w -> B K c h w', K=K, B=B, h=h, w=w)  #\n","\t\t\te = rearrange(e, '(K B) c h w -> B K c h w', K=K, B=B, h=h, w=w)  #\n","\t\t\tw = F.softmax(f, 1)\n","\t\t\te = (w * e).sum(1)\n","\t\t\tencoder[i] = e\n","\n","\t\tfeature = encoder[-1]\n","\t\tskip = encoder[:-1][::-1]\n","\t\tlast, decoder = self.decoder1(feature, skip)\n","\t\tlogit1 = self.logit1(last)\n","\n","\t\t#----------------------\n","\t\tx = last #.detach()\n","\t\t#x = F.avg_pool2d(x,kernel_size=2,stride=2)\n","\t\tencoder = []\n","\t\te = self.encoder2\n","\t\tx = e.layer1(x); encoder.append(x)\n","\t\tx = e.layer2(x); encoder.append(x)\n","\t\tx = e.layer3(x); encoder.append(x)\n","\t\tx = e.layer4(x); encoder.append(x)\n","\n","\t\tfeature = encoder[-1]\n","\t\tskip = encoder[:-1][::-1]\n","\t\tlast, decoder = self.decoder2(feature, skip)\n","\t\tlogit2 = self.logit2(last)\n","\t\tlogit2 = F.interpolate(logit2, size=(H, W), mode='bilinear', align_corners=False, antialias=True)\n","\n","\t\toutput = {\n","\t\t\t'ink' : torch.sigmoid(logit2),\n","\t\t}\n","\t\treturn output\n","\n","def run_check_net():\n","\n","\theight,width =  CFG.crop_size, CFG.crop_size\n","\tdepth = CFG.infer_fragment_z[1]-CFG.infer_fragment_z[0]\n","\tbatch_size = 3\n","\n","\tbatch = {\n","\t\t'volume' : torch.from_numpy( np.random.choice(256, (batch_size, depth, height, width))).cuda().float(),\n","\t}\n","\tnet = Net().cuda()\n","\n","\twith torch.no_grad():\n","\t\twith torch.cuda.amp.autocast(enabled=True):\n","\t\t\toutput = net(batch)\n","\n","\t#---\n","\tprint('batch')\n","\tfor k, v in batch.items():\n","\t\tprint(f'{k:>32} : {v.shape} ')\n","\n","\tprint('output')\n","\tfor k, v in output.items():\n","\t\tprint(f'{k:>32} : {v.shape} ')\n","\n","\n","run_check_net()\n","print('net ok !!!')"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T14:27:26.348719Z","iopub.status.busy":"2023-05-23T14:27:26.348382Z","iopub.status.idle":"2023-05-23T14:28:40.442741Z","shell.execute_reply":"2023-05-23T14:28:40.441801Z","shell.execute_reply.started":"2023-05-23T14:27:26.348686Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0 /kaggle/input/ink-01-weight/fix-rot-00005904.model.pth\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/ink-01-weight/fix-rot-00005904.model.pth'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/fummicc1/codes/Kaggle/kaggle-ink-detection/lb0-68-one-fold-stacked-unet.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 177>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.50/home/fummicc1/codes/Kaggle/kaggle-ink-detection/lb0-68-one-fold-stacked-unet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=191'>192</a>\u001b[0m \u001b[39mprint\u001b[39m(i,f)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.50/home/fummicc1/codes/Kaggle/kaggle-ink-detection/lb0-68-one-fold-stacked-unet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=192'>193</a>\u001b[0m n \u001b[39m=\u001b[39m Net()\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.50/home/fummicc1/codes/Kaggle/kaggle-ink-detection/lb0-68-one-fold-stacked-unet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=193'>194</a>\u001b[0m f \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(f, map_location\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m storage, loc: storage)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.50/home/fummicc1/codes/Kaggle/kaggle-ink-detection/lb0-68-one-fold-stacked-unet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=194'>195</a>\u001b[0m \u001b[39mprint\u001b[39m(n\u001b[39m.\u001b[39mload_state_dict(f[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m], strict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))  \u001b[39m# True\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.50/home/fummicc1/codes/Kaggle/kaggle-ink-detection/lb0-68-one-fold-stacked-unet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=195'>196</a>\u001b[0m net\u001b[39m.\u001b[39mappend(n)\n","File \u001b[0;32m~/anaconda3/envs/ink-detection-3_8/lib/python3.8/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n","File \u001b[0;32m~/anaconda3/envs/ink-detection-3_8/lib/python3.8/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n","File \u001b[0;32m~/anaconda3/envs/ink-detection-3_8/lib/python3.8/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/ink-01-weight/fix-rot-00005904.model.pth'"]}],"source":["###### infer here !!!!\n","#https://gist.github.com/janpaul123/ca3477c1db6de4346affca37e0e3d5b0\n","def mask_to_rle(mask):\n","    m = mask.reshape(-1)\n","    #m = np.where(mask > threshold, 1, 0).astype(np.uint8)\n","\n","    s = np.array((m[:-1] == 0) & (m[1:] == 1))\n","    e = np.array((m[:-1] == 1) & (m[1:] == 0))\n","\n","    s_index = np.where(s)[0] + 2\n","    e_index = np.where(e)[0] + 2\n","    length = e_index - s_index\n","    rle = ' '.join(map(str, sum(zip(s_index, length), ())))\n","    return rle\n","\n","def metric_to_text(ink, label, mask):\n","\ttext = []\n","\n","\tp = ink.reshape(-1)\n","\tt = label.reshape(-1)\n","\tpos = np.log(np.clip(p,1e-7,1))\n","\tneg = np.log(np.clip(1-p,1e-7,1))\n","\tbce = -(t*pos +(1-t)*neg).mean()\n","\ttext.append(f'bce={bce:0.5f}')\n","\n","\n","\tmask_sum = mask.sum()\n","\t#print(f'{threshold:0.1f}, {precision:0.3f}, {recall:0.3f}, {fpr:0.3f},  {dice:0.3f},  {score:0.3f}')\n","\ttext.append('p_sum  th   prec   recall   fpr   dice   score')\n","\ttext.append('-----------------------------------------------')\n","\tfor threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n","\t\tp = ink.reshape(-1)\n","\t\tt = label.reshape(-1)\n","\t\tp = (p > threshold).astype(np.float32)\n","\t\tt = (t > 0.5).astype(np.float32)\n","\n","\t\ttp = p * t\n","\t\tprecision = tp.sum() / (p.sum() + 0.0001)\n","\t\trecall = tp.sum() / t.sum()\n","\n","\t\tfp = p * (1 - t)\n","\t\tfpr = fp.sum() / (1 - t).sum()\n","\n","\t\tbeta = 0.5\n","\t\t#  0.2*1/recall + 0.8*1/prec\n","\t\tscore = beta * beta / (1 + beta * beta) * 1 / recall + 1 / (1 + beta * beta) * 1 / precision\n","\t\tscore = 1 / score\n","\n","\t\tdice = 2 * tp.sum() / (p.sum() + t.sum())\n","\t\tp_sum = p.sum()/mask_sum\n","\n","\t\t# print(fold, threshold, precision, recall, fpr,  score)\n","\t\ttext.append( f'{p_sum:0.2f}, {threshold:0.2f}, {precision:0.3f}, {recall:0.3f}, {fpr:0.3f},  {dice:0.3f},  {score:0.3f}')\n","\ttext = '\\n'.join(text)\n","\treturn text\n","\n","def make_infer_mask():\n","\ts = CFG.crop_size\n","\tf = CFG.crop_fade\n","\tx = np.linspace(-1, 1, s)\n","\ty = np.linspace(-1, 1, s)\n","\txx, yy = np.meshgrid(x, y)\n","\td = 1 - np.maximum(np.abs(xx), np.abs(yy))\n","\td1 = np.clip(d, 0, f / s * 2)\n","\td1 = d1 / d1.max()\n","\tinfer_mask = d1\n","\treturn infer_mask\n","\n","\n","\n","def infer_one(net, d):\n","\tnum_net = len(net)\n","\tfor i in range(num_net):\n","\t\tnet[i] = net[i].cuda()\n","\t\tnet[i] = net[i].eval()\n","\n","\t#get coord\n","\tcrop_size  = CFG.crop_size\n","\tstride = CFG.stride\n","\tH,W,D  = d.volume.shape\n","\n","\t##pad #assume H,W >size\n","\tpx, py = W % stride, H % stride\n","\tif (px != 0) or (py != 0):\n","\t\tpx = stride - px\n","\t\tpy = stride - py\n","\t\tpad_volume = np.pad(d.volume, [(0, py), (0, px), (0, 0)], constant_values=0)\n","\telse:\n","\t\tpad_volume = d.volume\n","\n","\tpH, pW, _  = pad_volume.shape\n","\tx = np.arange(0,pW-crop_size+1,stride)\n","\ty = np.arange(0,pH-crop_size+1,stride)\n","\tx,y = np.meshgrid(x,y)\n","\txy  = np.stack([x,y],-1).reshape(-1,2)\n","\tprint('H,W,pH,pW,len(xy)',H,W,pH,pW,len(xy))\n","\n","\t#---\n","\tinfer_mask = make_infer_mask()\n","\tprobability = np.zeros((pH,pW))\n","\tcount = np.zeros((pH,pW))\n","\n","\tstart_timer = timer()\n","\tbatch_iter = np.array_split(xy, len(xy)//6)\n","\tfor t, xy0 in enumerate(batch_iter):\n","\t\t#print('\\r', t, len(batch_iter), end='')\n","\n","\t\tvolume =[]\n","\t\tfor x0,y0 in xy0 :\n","\t\t\tv = pad_volume[y0:y0 + crop_size, x0:x0 + crop_size]\n","\t\t\tvolume.append(v)\n","\t\tvolume = np.stack(volume)\n","\t\tvolume = np.ascontiguousarray(volume.transpose(0,3,1,2))\n","\t\tvolume = volume/255\n","\t\tvolume = torch.from_numpy(volume).float().cuda()\n","\t\t##print(volume.shape)\n","\n","\t\tbatch = { 'volume': volume }\n","\n","\t\tk = 0\n","\t\tc = 0\n","\t\twith torch.no_grad():\n","\t\t\twith torch.cuda.amp.autocast(enabled=True):\n","\t\t\t\tfor i in range(num_net):\n","\t\t\t\t\tif not CFG.is_tta:\n","\t\t\t\t\t\toutput = net[i](batch)\n","\t\t\t\t\t\tk += output['ink'].data.cpu().numpy()\n","\t\t\t\t\t\tc += 1\n","\n","\t\t\t\t\t#--\n","\t\t\t\t\tif CFG.is_tta: #tta\n","\t\t\t\t\t\tpass\n","\t\t\t\t\t\tv = [\n","\t\t\t\t\t\t\tvolume,\n","\t\t\t\t\t\t\ttorch.rot90(volume, k=1, dims=(-2, -1)),\n","\t\t\t\t\t\t\ttorch.rot90(volume, k=2, dims=(-2, -1)),\n","\t\t\t\t\t\t\ttorch.rot90(volume, k=3, dims=(-2, -1)),\n","\t\t\t\t\t\t]\n","\t\t\t\t\t\tK=len(v)\n","\t\t\t\t\t\tbatch = {\n","\t\t\t\t\t\t\t'volume': torch.cat(v,0)\n","\t\t\t\t\t\t}\n","\t\t\t\t\t\toutput = net[i](batch)\n","\t\t\t\t\t\tink = output['ink']\n","\n","\t\t\t\t\t\tB,_,h,w = volume.shape\n","\t\t\t\t\t\tink = ink.reshape(K, B, 1, h, w)\n","\t\t\t\t\t\tink = [\n","\t\t\t\t\t\t\tink[0],\n","\t\t\t\t\t\t\ttorch.rot90(ink[1], k=-1, dims=(-2, -1)),\n","\t\t\t\t\t\t\ttorch.rot90(ink[2], k=-2, dims=(-2, -1)),\n","\t\t\t\t\t\t\ttorch.rot90(ink[3], k=-3, dims=(-2, -1)),\n","\t\t\t\t\t\t]\n","\t\t\t\t\t\tink = torch.stack(ink, dim=0)\n","\t\t\t\t\t\tink = ink.mean(0)\n","\n","\t\t\t\t\t\tk += ink.data.cpu().numpy()\n","\t\t\t\t\t\tc += 1\n","\t\t\t\t\t#--\n","\t\tk = k/c\n","\t\t##print(k.shape)\n","\n","\t\tbatch_size = len(k)\n","\t\tfor b in range(batch_size):\n","\t\t\tx0,y0 = xy0[b]\n","\t\t\tprobability[y0:y0 + crop_size, x0:x0 + crop_size] += k[b,0]*infer_mask\n","\t\t\tcount[y0:y0 + crop_size, x0:x0 + crop_size] += infer_mask\n","\t\tprint(f'\\r @infer_one(): {t} / {len(batch_iter)} : {time_to_str(timer() - start_timer, \"sec\")}', end='', flush=True)\n","\tprint('')\n","\tprobability = probability/(count+0.000001)\n","\tprobability = probability[:H,:W]\n","\treturn probability\n","\n","\n","\n","######################################\n","if ('skip_fake_test' in CFG.mode) and (is_skip_test):\n","\tsubmit_df = pd.DataFrame({\n","\t\t'Id': valid_id,\n","\t\t'Predicted':['1 2', '1 2']\n","\t})\n","else:\n","    \n","    checkpoint=[\n","        #'/kaggle/input/ink-01-weight/bug-00007920.model.pth',\n","        '/kaggle/input/ink-01-weight/fix-rot-00005904.model.pth',\n","    ]\n","\n","    #----\n","    net = []\n","    for i,f in enumerate(checkpoint):\n","        print(i,f)\n","        n = Net()\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        print(n.load_state_dict(f['state_dict'], strict=True))  # True\n","        net.append(n)\n","\n","    #----\n","    print(cfg_to_text())\n","    print('')\n","    submission = defaultdict(list)\n","    for t,fragment_id in enumerate(valid_id):\n","        d = read_data1(fragment_id)\n","\n","        print('==================================')\n","        print('fragment_id', d.fragment_id)\n","        print('\\tmask', d.mask.shape)\n","        print('\\tvolume', d.volume.shape)\n","        print('CFG.stride', CFG.stride)\n","        print('CFG.crop_size', CFG.crop_size)  \n","        print('')\n","\n","        probability = infer_one(net, d)\n","        print('probability', probability.shape)\n","\n","        probability = d.mask*probability\n","        predict = (probability>0.55).astype(np.uint8)\n","\n","        #----\n","        submission['Id'].append(fragment_id)\n","        submission['Predicted'].append(mask_to_rle(predict))\n","\n","        #----\n","        probability8 = (probability * 255).astype(np.uint8)\n","        plt.figure(t), plt.imshow(probability8, cmap='gray')\n","        #plt.waitforbuttonpress()\n","        if 'train' in CFG.mode:\n","            text = metric_to_text(probability, d.label, d.mask)\n","            print(text)\n","        print('')\n","\n","    print('')\n","    submit_df = pd.DataFrame.from_dict(submission)\n","\n","print('')\n","print(cfg_to_text())\n","submit_df.to_csv('submission.csv', index=False)\n","print(submit_df)\n","print('submission.csv ok!!!')\n","\n","'''\n"," \n","\n","'''"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":4}
