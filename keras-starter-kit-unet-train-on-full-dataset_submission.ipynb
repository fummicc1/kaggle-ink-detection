{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Keras starter kit [full training set, UNet]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.741181Z","iopub.status.busy":"2023-05-10T15:03:39.740765Z","iopub.status.idle":"2023-05-10T15:03:39.750574Z","shell.execute_reply":"2023-05-10T15:03:39.749341Z","shell.execute_reply.started":"2023-05-10T15:03:39.741144Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","import glob\n","import time\n","import PIL.Image as Image\n","import matplotlib.pyplot as plt\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","import matplotlib.patches as patches\n","from tqdm import tqdm\n","import cv2\n","\n","# Data config\n","# DATA_DIR = '/kaggle/input/vesuvius-challenge-ink-detection/'\n","DATA_DIR = \".\"\n","BUFFER = 128  # Half-size of papyrus patches we'll use as model inputs\n","Z_DIM = 64  # Number of slices in the z direction. Max value is 64 - Z_START\n","Z_START = 0  # Offset of slices in the z direction\n","SHARED_HEIGHT = 2000  # Height to resize all papyrii\n","\n","# (y, x)\n","val_location = (600, 500)\n","val_zone_size = (500, 300)\n","\n","# Model config\n","BATCH_SIZE = 64\n","USE_MIXED_PRECISION = False\n","USE_JIT_COMPILE = False\n","\n","device = torch.device(\"cuda\")\n","threshold = 0.2\n","num_workers = 2\n","exp = 1e-7"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["all_median = [\n","    19576., 19582., 19597., 19609., 19616., 19626., 19638., 19642.,\n","       19650., 19653., 19665., 19683., 19709., 19748., 19795., 19857.,\n","       19945., 20054., 20184., 20347., 20563., 20834., 21153., 21523.,\n","       21910., 22263., 22526., 22619., 22453., 21935., 21035., 19957.,\n","       18981., 18246., 17804., 17672., 17848., 18266., 18839., 19476.,\n","       20093., 20650., 21129., 21525., 21847., 22108., 22318., 22490.,\n","       22630., 22746., 22841., 22923., 22992., 23051., 23099., 23138.,\n","       23170., 23198., 23222., 23243., 23260., 23276., 23288., 23296.\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_MAD = [\n","    12430., 12460., 12490., 12522., 12562., 12605., 12642., 12679.,\n","       12711., 12753., 12794., 12832., 12866., 12890., 12919., 12942.,\n","       12956., 12974., 13013., 13059., 13100., 13154., 13245., 13367.,\n","       13545., 13779., 14049., 14339., 14602., 14803., 14875., 14564.,\n","       13634., 12099., 10137.,  8517.,  7498.,  6681.,  5969.,  5349.,\n","        4829.,  4401.,  4055.,  3787.,  3577.,  3408.,  3272.,  3159.,\n","        3065.,  2986.,  2920.,  2862.,  2809.,  2762.,  2723.,  2692.,\n","        2667.,  2644.,  2623.,  2604.,  2589.,  2575.,  2564.,  2558.\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def resize(img):\n","    current_height, current_width = img.shape    \n","    aspect_ratio = current_width / current_height\n","    new_width = int(SHARED_HEIGHT * aspect_ratio)\n","    new_size = (new_width, SHARED_HEIGHT)\n","    # (W, H)の順で渡すが結果は(H, W)になっている\n","    img = cv2.resize(img, new_size)\n","    return img\n","\n","def load_mask(split, index):\n","    img = cv2.imread(f\"{DATA_DIR}/{split}/{index}/mask.png\", 0) // 255\n","    img = resize(img)    \n","    return img\n","\n","\n","def load_labels(split, index):\n","    img = cv2.imread(f\"{DATA_DIR}/{split}/{index}/inklabels.png\", 0) // 255\n","    img = resize(img)\n","    return img\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def load_volume(split, index):\n","    # Load the 3d x-ray scan, one slice at a time\n","    z_slices_fnames = sorted(glob.glob(f\"{DATA_DIR}/{split}/{index}/surface_volume/*.tif\"))[Z_START:Z_START + Z_DIM]\n","    z_slices = []\n","    for z, filename in  tqdm(enumerate(z_slices_fnames)):\n","        img = cv2.imread(filename, -1)\n","        img = resize(img)\n","        z_slices.append(img)\n","    return np.stack(z_slices, axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def sample_random_location(shape):\n","    random_train_x = np.random.randint(low=BUFFER, high=shape[1] - BUFFER - 1, size=())\n","    random_train_y = np.random.randint(low=BUFFER, high=shape[0] - BUFFER - 1, size=())\n","    random_train_location = np.stack([random_train_y, random_train_x], axis=-1)\n","    return random_train_location\n","\n","\n","def is_in_masked_zone(location, mask):\n","    return mask[location[0], location[1]] > 0\n","\n","def is_in_val_zone(location, val_location, val_zone_size):\n","    x = location[1]\n","    y = location[0]\n","    x_match = val_location[1] - BUFFER <= x <= val_location[1] + val_zone_size[1] + BUFFER\n","    y_match = val_location[0] - BUFFER <= y <= val_location[0] + val_zone_size[0] + BUFFER\n","    return x_match and y_match\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["printed = False\n","\n","def extract_subvolume(location, volume):\n","    global printed\n","    # print(np.unique(volume, return_counts=True, return_index=True))\n","    x = location[0]\n","    y = location[1]\n","    subvolume = volume[x-BUFFER:x+BUFFER, y-BUFFER:y+BUFFER, :].astype(np.float32)\n","    # print(\"subvolume[:, :, 0]\", subvolume[:, :, 0])\n","    median = np.full_like(subvolume, all_median).astype(np.float32)\n","    MAD = np.full_like(subvolume, all_MAD).astype(np.float32)\n","    # mean = np.mean(subvolume, axis=2)\n","    # mean = np.stack([mean for i in range(Z_DIM)], axis=2) + exp\n","    # MAD = median_abs_deviation(subvolume, axis=2)\n","    # print(\"MAD\", MAD[0, 0, :])\n","    # print(\"mean\", mean)\n","    # print(\"median\", median[0, 0, :])\n","    \n","    subvolume = (subvolume - median) / MAD\n","    \n","    if not printed:\n","        print(\"subvolume after taking care of median and MAD\", subvolume)\n","        printed = True\n","    \n","    return subvolume"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import OneHotEncoder\n","\n","class SubvolumeDataset(Dataset):\n","    def __init__(self, locations, volume, labels, buffer, is_train: bool, return_location: bool = False):\n","        self.locations = locations\n","        self.volume = volume\n","        self.labels = labels        \n","        self.buffer = buffer\n","        self.is_train = is_train\n","        self.return_location = return_location\n","\n","    def __len__(self):\n","        return len(self.locations)\n","\n","    def __getitem__(self, idx):\n","        label = None\n","        location = np.array(self.locations[idx])\n","        y, x = location[0], location[1]\n","\n","        subvolume = extract_subvolume(location, self.volume)        \n","        # print(\"subvolume\", subvolume)\n","        # print(\"labels\", labels)\n","        # subvolume = subvolume.numpy()\n","        subvolume = subvolume\n","        \n","        if self.labels is not None:\n","            label = self.labels[y - self.buffer:y + self.buffer, x - self.buffer:x + self.buffer]\n","            # print(\"label\", label)\n","            # n_category = 2\n","            # label = np.eye(n_category)[label]\n","            label = np.stack([label], axis=-1)\n","            # label = label.numpy()\n","            # print(\"label.shape\", label.shape\n","        \n","        if self.is_train and label is not None:            \n","            \n","            # print(\"label\", label.dtype)\n","            # print(\"subvolume in dataset (before aug)\", subvolume)            \n","            # performed = A.Compose([            \n","            #     A.ToFloat(max_value=possible_max_input),\n","            #     # A.RandomBrightnessContrast(),\n","            #     # A.HorizontalFlip(),\n","            #     # A.VerticalFlip(),  \n","            #     # A.Normalize(\n","            #     #     mean=[mean],\n","            #     #     std=[std],\n","            #     # ),\n","            #     A.FromFloat(max_value=possible_max_input),\n","            # ])(image=subvolume, mask=label)\n","            # subvolume = performed[\"image\"]            \n","            # label = performed[\"mask\"]\n","            # print(\"subvolume in dataset (after aug)\", subvolume)\n","            # print(\"label\", label.dtype)\n","            # print(\"subvolume\", subvolume.dtype)\n","            # →C, H, W\n","            subvolume = torch.from_numpy(subvolume.transpose(2, 0, 1).astype(np.float64))\n","            # print(performed)\n","            # print(subvolume.shape, label.shape)\n","            # H, W, C → C, H, W\n","            label = torch.from_numpy(label.transpose(2, 0, 1).astype(np.uint8)) \n","        else:            \n","            # performed = A.Compose([  \n","            #     A.ToFloat(max_value=possible_max_input),                \n","            #     # A.Normalize(\n","            #     #     mean=[mean],\n","            #     #     std=[std],\n","            #     # ),\n","            #     A.FromFloat(max_value=possible_max_input),\n","            # ])(image=subvolume)\n","            # subvolume = performed[\"image\"]\n","            subvolume = torch.from_numpy(subvolume.transpose(2, 0, 1).astype(np.float64))\n","            if label is not None:\n","                label = torch.from_numpy(label.transpose(2, 0, 1).astype(np.uint8)) \n","        if self.return_location:\n","            return subvolume, location\n","        return subvolume, label        "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.754332Z","iopub.status.busy":"2023-05-10T15:03:39.753960Z","iopub.status.idle":"2023-05-10T15:03:39.773134Z","shell.execute_reply":"2023-05-10T15:03:39.772207Z","shell.execute_reply.started":"2023-05-10T15:03:39.754292Z"},"trusted":true},"outputs":[],"source":["\n","class UNet(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UNet, self).__init__()\n","\n","        def conv_block(in_channels, out_channels):\n","            return nn.Sequential(                \n","                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU(),\n","            )\n","\n","        def transpose_conv_block(in_channels, out_channels):\n","            return nn.Sequential(                \n","                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU(),\n","            )\n","\n","        self.encoder = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv2d(in_channels if i == 2 else 64 * 2**(i - 1), 64 * 2**i, kernel_size=3, stride=2, padding=1),\n","                nn.BatchNorm2d(64 * 2**i),\n","                nn.ReLU(),\n","                nn.Conv2d(64 * 2**i, 64 * 2**i, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(64 * 2**i),\n","                nn.ReLU(),\n","            )\n","            for i in range(2, 4)\n","        ])\n","\n","\n","        self.middle = nn.Sequential(\n","            conv_block(512, 512),\n","            conv_block(512, 512),\n","        )\n","        \n","        self.decoder = nn.ModuleList([\n","            nn.Sequential(\n","                transpose_conv_block(2 ** (i + 7), 2 ** (i + 6)),\n","                transpose_conv_block(2 ** (i + 6), 2 ** (i + 5)),\n","                nn.Upsample(scale_factor=2, mode=\"nearest\"),\n","            )\n","            for i in range(3, 1, -1)\n","        ])\n","        self.final_decoder = nn.Sequential(\n","            nn.Conv2d(128, 32, kernel_size=3, padding=1),\n","            nn.Conv2d(32, out_channels, kernel_size=3, padding=1),\n","        )\n","        self.activation = nn.Identity()\n","\n","    def forward(self, x):\n","        # print(\"input:\", x)\n","        skip_connections = []\n","        for layer in self.encoder:\n","            x = layer(x)\n","            skip_connections.append(x)\n","\n","        x = self.middle(x)\n","        \n","        # print(\"encoder ok\", x)\n","        for i, layer in enumerate(self.decoder):            \n","            # print(f\"decoder will {i}: ok\", x.shape)\n","            x = torch.cat([x, skip_connections[-i-1]], dim=1)  # Concatenate along channel dimension\n","            # print(f\"decoder with skip connection {i}: ok\", x.shape)            \n","            x = layer(x)            \n","            # print(f\"decoder {i}: ok\", x)\n","        # print(\"decoder ok\")\n","        x = self.final_decoder(x)\n","        x = self.activation(x)\n","        # print(\"final out\", x)\n","        return x"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.775244Z","iopub.status.busy":"2023-05-10T15:03:39.774877Z","iopub.status.idle":"2023-05-10T15:03:39.789220Z","shell.execute_reply":"2023-05-10T15:03:39.788194Z","shell.execute_reply.started":"2023-05-10T15:03:39.775205Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.792507Z","iopub.status.busy":"2023-05-10T15:03:39.791249Z","iopub.status.idle":"2023-05-10T15:03:39.864099Z","shell.execute_reply":"2023-05-10T15:03:39.862787Z","shell.execute_reply.started":"2023-05-10T15:03:39.792466Z"},"trusted":true},"outputs":[],"source":["model = UNet(Z_DIM, 2)\n","model = nn.DataParallel(model)\n","# model.load_state_dict(torch.load(f\"/kaggle/input/ink-detection/model.pt\"))\n","model.load_state_dict(torch.load(\"model.pt\"))\n","model = model.to(device)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load up the training data"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.881907Z","iopub.status.busy":"2023-05-10T15:03:39.881465Z","iopub.status.idle":"2023-05-10T15:03:39.904353Z","shell.execute_reply":"2023-05-10T15:03:39.903210Z","shell.execute_reply.started":"2023-05-10T15:03:39.881867Z"},"trusted":true},"outputs":[],"source":["\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from tqdm import tqdm\n","\n","def compute_predictions_map(split, index):\n","    \n","    print(f\"Load data for {split}/{index}\")\n","\n","    test_volume = load_volume(split=split, index=index)\n","    test_mask = load_mask(split=split, index=index)    \n","\n","    test_locations = []\n","    stride = BUFFER // 2\n","    for y in range(BUFFER, test_volume.shape[0] - BUFFER, stride):\n","        for x in range(BUFFER, test_volume.shape[1] - BUFFER, stride):\n","            test_locations.append((y, x))\n","\n","    print(f\"{len(test_locations)} test locations (before filtering by mask)\")\n","\n","    # filter locations inside the mask\n","    test_locations = [loc for loc in test_locations if is_in_masked_zone(loc, test_mask)]\n","    \n","    print(f\"{len(test_locations)} test locations (after filtering by mask)\")\n","\n","    test_ds = SubvolumeDataset(test_locations, test_volume, None, BUFFER, is_train=False, return_location=True)\n","    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=num_workers)\n","\n","    # shape: (X, Y, C)\n","    predictions_map = np.zeros_like(test_volume[:, :, 0]).transpose((1, 0))[:, :, np.newaxis].astype(np.float64)\n","    \n","    print(\"test_volume.shape\", test_volume.shape)\n","    print(\"predictions_map.shape\", predictions_map.shape)\n","\n","    print(f\"Compute predictions\")\n","\n","    model.eval()  # set model to evaluation mode\n","    with torch.no_grad():    \n","        for patch_batch, loc_batch in tqdm(test_loader):\n","            loc_batch = loc_batch.to(device).long()\n","            patch_batch = patch_batch.to(device).float()\n","            predictions = model(patch_batch)\n","            # print(\"predictions\", predictions)\n","            predictions = nn.Softmax(dim=1)(predictions)\n","            predictions: torch.Tensor = predictions[:, 1, :, :].unsqueeze(dim=1)\n","            # print(\"Softmaxed predictions where conf is gt threshold\", predictions[predictions.gt(threshold)])\n","            # →(BATCH, W, H, C)\n","            predictions = torch.permute(predictions, (0, 3, 2, 1))\n","            predictions = predictions.cpu().numpy()  # move predictions to cpu and convert to numpy\n","            for (y, x), pred in zip(loc_batch, predictions):\n","                # print(\"index: \", index ,\"x, y, pred\", x.item(), y.item(), pred[BUFFER, BUFFER, :].item(), file=open('log.out', 'a'))\n","                predictions_map[\n","                    x - BUFFER : x + BUFFER, y - BUFFER : y + BUFFER, :\n","                ][pred > threshold] = 1\n","    print(\"predictions_map\", predictions_map, file=open(\"predictions_map\", \"w\"))\n","    return predictions_map\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.906477Z","iopub.status.busy":"2023-05-10T15:03:39.905840Z","iopub.status.idle":"2023-05-10T15:03:39.916814Z","shell.execute_reply":"2023-05-10T15:03:39.915804Z","shell.execute_reply.started":"2023-05-10T15:03:39.906254Z"},"trusted":true},"outputs":[],"source":["from skimage.transform import resize as resize_ski\n","import pathlib"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.918543Z","iopub.status.busy":"2023-05-10T15:03:39.918095Z","iopub.status.idle":"2023-05-10T15:03:39.929658Z","shell.execute_reply":"2023-05-10T15:03:39.928498Z","shell.execute_reply.started":"2023-05-10T15:03:39.918498Z"},"trusted":true},"outputs":[],"source":["def rle(predictions_map, threshold):\n","    flat_img = (np.where(predictions_map.flatten() >= threshold, 1, 0)).astype(np.uint8)\n","    \n","    # Add padding at the beginning and end\n","    flat_img = np.pad(flat_img, pad_width=1, mode='constant', constant_values=0)\n","\n","    starts = np.where((flat_img[:-1] == 0) & (flat_img[1:] == 1))[0]\n","    ends = np.where((flat_img[:-1] == 1) & (flat_img[1:] == 0))[0]\n","\n","    lengths = ends - starts\n","    \n","    print(lengths.shape)\n","\n","    return \" \".join(map(str, np.c_[starts, lengths].flatten()))\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.933503Z","iopub.status.busy":"2023-05-10T15:03:39.930806Z","iopub.status.idle":"2023-05-10T15:03:39.945903Z","shell.execute_reply":"2023-05-10T15:03:39.944714Z","shell.execute_reply.started":"2023-05-10T15:03:39.933458Z"},"trusted":true},"outputs":[],"source":["def update_submission(predictions_map, index):\n","    rle_ = rle(predictions_map, threshold=threshold)\n","    print(f\"{index},\" + rle_, file=open('submission.csv', 'a'))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.948169Z","iopub.status.busy":"2023-05-10T15:03:39.947490Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Load data for test/a\n"]},{"name":"stderr","output_type":"stream","text":["32it [00:03, 10.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["141942 test locations (before filtering by mask)\n","Compute predictions\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2817/2817 [01:02<00:00, 44.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["compute_predictions_map end\n","original_size end\n","resize_ski end\n","update_submission end\n","Load data for test/b\n"]},{"name":"stderr","output_type":"stream","text":["32it [00:04,  7.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["70602 test locations (before filtering by mask)\n","Compute predictions\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1196/1196 [00:24<00:00, 48.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["compute_predictions_map end\n","original_size end\n","resize_ski end\n","update_submission end\n"]}],"source":["print(\"Id,Predicted\", file=open('submission.csv', 'w'))\n","folder = pathlib.Path(DATA_DIR) / \"test\"\n","for p in list(folder.iterdir()):\n","    index = p.stem\n","    predictions_map = compute_predictions_map(split=\"test\", index=index)\n","    original_size = cv2.imread(DATA_DIR + f\"/test/{index}/mask.png\", 0).shape[:2]\n","    # W, H, C → H, W, C\n","    predictions_map = predictions_map.transpose((1, 0, 2))    \n","    predictions_map = resize_ski(predictions_map, (original_size[0], original_size[1], 1)).squeeze(axis=-1)    \n","    print(\"original predictions_map size\", predictions_map.shape)    \n","    # H, W → W, H\n","    update_submission(predictions_map.transpose((1, 0)), index)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
