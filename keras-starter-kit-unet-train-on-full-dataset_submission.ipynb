{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Keras starter kit [full training set, UNet]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Setup"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.741181Z","iopub.status.busy":"2023-05-10T15:03:39.740765Z","iopub.status.idle":"2023-05-10T15:03:39.750574Z","shell.execute_reply":"2023-05-10T15:03:39.749341Z","shell.execute_reply.started":"2023-05-10T15:03:39.741144Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","import glob\n","import time\n","import PIL.Image as Image\n","import matplotlib.pyplot as plt\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","import matplotlib.patches as patches\n","from tqdm import tqdm\n","import cv2\n","\n","# Data config\n","# DATA_DIR = '/kaggle/input/vesuvius-challenge-ink-detection/'\n","DATA_DIR = \".\"\n","BUFFER = 64  # Half-size of papyrus patches we'll use as model inputs\n","Z_LIST = list(range(0, 65, 4))  # Offset of slices in the z direction\n","Z_DIM = len(Z_LIST)  # Number of slices in the z direction. Max value is 64 - Z_START\n","SHARED_HEIGHT = 4000  # Height to resize all papyrii\n","\n","# (y, x)\n","val_location = (600, 500)\n","val_zone_size = (1000, 500)\n","\n","# Model config\n","BATCH_SIZE = 64\n","USE_MIXED_PRECISION = False\n","USE_JIT_COMPILE = False\n","\n","device = torch.device(\"cuda\")\n","threshold = 0.25\n","num_workers = 2\n","exp = 1e-7"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["from scipy.stats import median_abs_deviation\n","\n","def calculate_MAD(volume):\n","    all_MAD = median_abs_deviation(volume, axis=[0, 1])\n","    return all_MAD\n","    \n","def calculate_median(volume):\n","    all_median = np.median(volume, axis=[0, 1])\n","    return all_median"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["all_median = np.array([19581., 19618., 19645., 19710., 19944., 20561., 21908., 22458.,\n","        18980., 17848., 20094., 21848., 22629., 22993., 23171., 23261.,\n","        23305.])"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["all_MAD = np.array([12424., 12561., 12718., 12864., 12953., 13099., 13550., 14592.,\n","        13639.,  7500.,  4828.,  3576.,  3067.,  2808.,  2666.,  2588.,\n","         2550.])"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"data":{"text/plain":["18.70078431372549"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["possible_max_input = ((2 ** 16 - 1) / all_median.min())\n","possible_max_input"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["def resize(img):\n","    current_height, current_width = img.shape    \n","    aspect_ratio = current_width / current_height\n","    new_width = int(SHARED_HEIGHT * aspect_ratio)\n","    new_size = (new_width, SHARED_HEIGHT)\n","    # (W, H)の順で渡すが結果は(H, W)になっている\n","    img = cv2.resize(img, new_size)\n","    return img\n","\n","def load_mask(split, index):\n","    img = cv2.imread(f\"{DATA_DIR}/{split}/{index}/mask.png\", 0) // 255\n","    img = resize(img)    \n","    return img\n","\n","\n","def load_labels(split, index):\n","    img = cv2.imread(f\"{DATA_DIR}/{split}/{index}/inklabels.png\", 0) // 255\n","    img = resize(img)\n","    return img\n"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":["def load_volume(split, index):\n","    # Load the 3d x-ray scan, one slice at a time\n","    all = sorted(glob.glob(f\"{DATA_DIR}/{split}/{index}/surface_volume/*.tif\"))\n","    z_slices_fnames = [all[i] for i in range(len(all)) if i in Z_LIST]\n","    assert len(z_slices_fnames) == Z_DIM\n","    z_slices = []\n","    for z, filename in  tqdm(enumerate(z_slices_fnames)):\n","        img = cv2.imread(filename, -1)\n","        img = resize(img)\n","        z_slices.append(img)\n","    return np.stack(z_slices, axis=-1)"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["def sample_random_location(shape):\n","    random_train_x = np.random.randint(low=BUFFER, high=shape[1] - BUFFER - 1, size=())\n","    random_train_y = np.random.randint(low=BUFFER, high=shape[0] - BUFFER - 1, size=())\n","    random_train_location = np.stack([random_train_y, random_train_x], axis=-1)\n","    return random_train_location\n","\n","\n","def is_in_masked_zone(location, mask):\n","    return mask[location[0], location[1]] > 0\n","\n","def is_in_val_zone(location, val_location, val_zone_size):\n","    x = location[1]\n","    y = location[0]\n","    x_match = val_location[1] - BUFFER <= x <= val_location[1] + val_zone_size[1] + BUFFER\n","    y_match = val_location[0] - BUFFER <= y <= val_location[0] + val_zone_size[0] + BUFFER\n","    return x_match and y_match\n"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["printed = False\n","\n","def extract_subvolume(location, volume):\n","    global printed\n","    # print(np.unique(volume, return_counts=True, return_index=True))\n","    x = location[0]\n","    y = location[1]\n","    subvolume = volume[x-BUFFER:x+BUFFER, y-BUFFER:y+BUFFER, :].astype(np.float32)\n","    # print(\"subvolume[:, :, 0]\", subvolume[:, :, 0])\n","    median = np.full_like(subvolume, all_median).astype(np.float32)\n","    MAD = np.full_like(subvolume, all_MAD).astype(np.float32)\n","    # mean = np.mean(subvolume, axis=2)\n","    # mean = np.stack([mean for i in range(Z_DIM)], axis=2) + exp\n","    # MAD = median_abs_deviation(subvolume, axis=2)\n","    # print(\"MAD\", MAD[0, 0, :])\n","    # print(\"mean\", mean)\n","    # print(\"median\", median[0, 0, :])\n","    \n","    subvolume = (subvolume - median) / MAD\n","    \n","    if not printed:\n","        print(\"subvolume after taking care of median and MAD\", subvolume)\n","        printed = True\n","    \n","    return subvolume"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import OneHotEncoder\n","\n","class SubvolumeDataset(Dataset):\n","    def __init__(self, locations, volume, labels, buffer, is_train: bool, return_location: bool = False):\n","        self.locations = locations\n","        self.volume = volume\n","        self.labels = labels        \n","        self.buffer = buffer\n","        self.is_train = is_train\n","        self.return_location = return_location\n","\n","    def __len__(self):\n","        return len(self.locations)\n","\n","    def __getitem__(self, idx):\n","        label = None\n","        location = np.array(self.locations[idx])\n","        y, x = location[0], location[1]\n","\n","        subvolume = extract_subvolume(location, self.volume)        \n","        # print(\"subvolume\", subvolume)\n","        # print(\"labels\", labels)\n","        # subvolume = subvolume.numpy()\n","        subvolume = subvolume\n","        \n","        if self.labels is not None:\n","            label = self.labels[y - self.buffer:y + self.buffer, x - self.buffer:x + self.buffer]\n","            # print(\"label\", label)\n","            # n_category = 2\n","            # label = np.eye(n_category)[label]\n","            label = np.stack([label], axis=-1)\n","            # label = label.numpy()\n","            # print(\"label.shape\", label.shape\n","        \n","        if self.is_train and label is not None:            \n","            \n","            # print(\"label\", label.dtype)\n","            # print(\"subvolume in dataset (before aug)\", subvolume)            \n","            performed = A.Compose([            \n","                A.ToFloat(max_value=possible_max_input),\n","                A.RandomBrightnessContrast(),\n","                A.HorizontalFlip(),\n","                A.VerticalFlip(),  \n","            #     # A.Normalize(\n","            #     #     mean=[mean],\n","            #     #     std=[std],\n","            #     # ),\n","                A.FromFloat(max_value=possible_max_input),\n","            ])(image=subvolume, mask=label)\n","            subvolume = performed[\"image\"]            \n","            label = performed[\"mask\"]\n","            # print(\"subvolume in dataset (after aug)\", subvolume)\n","            # print(\"label\", label.dtype)\n","            # print(\"subvolume\", subvolume.dtype)\n","            # →C, H, W\n","            subvolume = torch.from_numpy(subvolume.transpose(2, 0, 1).astype(np.float64))\n","            # print(performed)\n","            # print(subvolume.shape, label.shape)\n","            # H, W, C → C, H, W\n","            label = torch.from_numpy(label.transpose(2, 0, 1).astype(np.uint8)) \n","        else:\n","            performed = A.Compose([  \n","                A.ToFloat(max_value=possible_max_input),                \n","                # A.Normalize(\n","                #     mean=[mean],\n","                #     std=[std],\n","                # ),\n","                A.FromFloat(max_value=possible_max_input),\n","            ])(image=subvolume)\n","            subvolume = performed[\"image\"]\n","            subvolume = torch.from_numpy(subvolume.transpose(2, 0, 1).astype(np.float64))\n","            if label is not None:\n","                label = torch.from_numpy(label.transpose(2, 0, 1).astype(np.uint8)) \n","        if self.return_location:\n","            return subvolume, location\n","        return subvolume, label        "]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.754332Z","iopub.status.busy":"2023-05-10T15:03:39.753960Z","iopub.status.idle":"2023-05-10T15:03:39.773134Z","shell.execute_reply":"2023-05-10T15:03:39.772207Z","shell.execute_reply.started":"2023-05-10T15:03:39.754292Z"},"trusted":true},"outputs":[],"source":["\n","class UNet(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UNet, self).__init__()\n","\n","        def conv_block(in_channels, out_channels):\n","            return nn.Sequential(                \n","                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU(),\n","            )\n","\n","        def transpose_conv_block(in_channels, out_channels):\n","            return nn.Sequential(                \n","                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU(),\n","            )\n","\n","        self.encoder = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv2d(in_channels if i == 2 else 64 * 2**(i - 1), 64 * 2**i, kernel_size=3, stride=2, padding=1),\n","                nn.BatchNorm2d(64 * 2**i),\n","                nn.ReLU(),\n","                nn.Conv2d(64 * 2**i, 64 * 2**i, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(64 * 2**i),\n","                nn.ReLU(),\n","            )\n","            for i in range(2, 5)\n","        ])\n","\n","\n","        self.middle = nn.Sequential(\n","            conv_block(1024, 512),\n","            conv_block(512, 1024),\n","        )\n","        \n","        self.decoder = nn.ModuleList([\n","            nn.Sequential(\n","                transpose_conv_block(2 ** (i + 7), 2 ** (i + 6)),\n","                transpose_conv_block(2 ** (i + 6), 2 ** (i + 5)),\n","                nn.Upsample(scale_factor=2, mode=\"nearest\"),\n","            )\n","            for i in range(4, 1, -1)\n","        ])\n","        self.final_decoder = nn.Sequential(\n","            nn.Conv2d(128, 32, kernel_size=3, padding=1),\n","            nn.Conv2d(32, out_channels, kernel_size=3, padding=1),\n","        )\n","        self.activation = nn.Identity()\n","\n","    def forward(self, x):\n","        # print(\"input:\", x)\n","        skip_connections = []\n","        for layer in self.encoder:\n","            x = layer(x)\n","            skip_connections.append(x)\n","\n","        x = self.middle(x)\n","        \n","        # print(\"encoder ok\", x)\n","        for i, layer in enumerate(self.decoder):            \n","            # print(f\"decoder will {i}: ok\", x.shape)\n","            x = torch.cat([x, skip_connections[-i-1]], dim=1)  # Concatenate along channel dimension\n","            # print(f\"decoder with skip connection {i}: ok\", x.shape)            \n","            x = layer(x)            \n","            # print(f\"decoder {i}: ok\", x)\n","        # print(\"decoder ok\")\n","        x = self.final_decoder(x)\n","        x = self.activation(x)\n","        # print(\"final out\", x)\n","        return x"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.775244Z","iopub.status.busy":"2023-05-10T15:03:39.774877Z","iopub.status.idle":"2023-05-10T15:03:39.789220Z","shell.execute_reply":"2023-05-10T15:03:39.788194Z","shell.execute_reply.started":"2023-05-10T15:03:39.775205Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.792507Z","iopub.status.busy":"2023-05-10T15:03:39.791249Z","iopub.status.idle":"2023-05-10T15:03:39.864099Z","shell.execute_reply":"2023-05-10T15:03:39.862787Z","shell.execute_reply.started":"2023-05-10T15:03:39.792466Z"},"trusted":true},"outputs":[],"source":["model = UNet(Z_DIM, 2)\n","model = nn.DataParallel(model)\n","# model.load_state_dict(torch.load(f\"/kaggle/input/ink-detection/model.pt\"))\n","model.load_state_dict(torch.load(\"model.pt\"))\n","model = model.to(device)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load up the training data"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.881907Z","iopub.status.busy":"2023-05-10T15:03:39.881465Z","iopub.status.idle":"2023-05-10T15:03:39.904353Z","shell.execute_reply":"2023-05-10T15:03:39.903210Z","shell.execute_reply.started":"2023-05-10T15:03:39.881867Z"},"trusted":true},"outputs":[],"source":["\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from tqdm import tqdm\n","\n","def compute_predictions_map(split, index):\n","    global all_MAD, all_median\n","    \n","    print(f\"Load data for {split}/{index}\")\n","\n","    test_volume = load_volume(split=split, index=index)        \n","    test_mask = load_mask(split=split, index=index)    \n","    \n","    # all_MAD = calculate_MAD(test_volume)\n","    # all_median = calculate_median(test_volume)\n","\n","    test_locations = []\n","    stride = BUFFER // 2\n","    for y in range(BUFFER, test_volume.shape[0] - BUFFER, stride):\n","        for x in range(BUFFER, test_volume.shape[1] - BUFFER, stride):\n","            test_locations.append((y, x))\n","\n","    print(f\"{len(test_locations)} test locations (before filtering by mask)\")\n","\n","    # filter locations inside the mask\n","    test_locations = [loc for loc in test_locations if is_in_masked_zone(loc, test_mask)]\n","    \n","    print(f\"{len(test_locations)} test locations (after filtering by mask)\")\n","\n","    test_ds = SubvolumeDataset(test_locations, test_volume, None, BUFFER, is_train=False, return_location=True)\n","    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=num_workers)\n","\n","    # shape: (X, Y, C)\n","    predictions_map = np.zeros_like(test_volume[:, :, 0]).transpose((1, 0))[:, :, np.newaxis].astype(np.float64)\n","    \n","    print(\"test_volume.shape\", test_volume.shape)\n","    print(\"predictions_map.shape\", predictions_map.shape)\n","\n","    print(f\"Compute predictions\")\n","\n","    model.eval()  # set model to evaluation mode\n","    with torch.no_grad():    \n","        for patch_batch, loc_batch in tqdm(test_loader):\n","            loc_batch = loc_batch.to(device).long()\n","            patch_batch = patch_batch.to(device).float()\n","            predictions = model(patch_batch)\n","            # print(\"predictions\", predictions)\n","            predictions = nn.Softmax(dim=1)(predictions)            \n","            predictions: torch.Tensor = predictions[:, 1, :, :].unsqueeze(dim=1)\n","            # print(\"predictions\", predictions)\n","            # print(\"Softmaxed predictions where conf is gt threshold\", predictions[predictions.gt(threshold)])\n","            # →(BATCH, W, H, C)\n","            predictions = torch.permute(predictions, (0, 3, 2, 1))\n","            predictions = predictions.cpu().numpy()  # move predictions to cpu and convert to numpy\n","            for (y, x), pred in zip(loc_batch, predictions):\n","                # print(\"index: \", index ,\"x, y, pred\", x.item(), y.item(), pred[BUFFER, BUFFER, :].item(), file=open('log.out', 'a'))\n","                predictions_map[\n","                    x - BUFFER : x + BUFFER, y - BUFFER : y + BUFFER, :\n","                ][pred > threshold] = 1\n","    print(\"predictions_map\", predictions_map, file=open(\"predictions_map\", \"w\"))\n","    return predictions_map\n"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.906477Z","iopub.status.busy":"2023-05-10T15:03:39.905840Z","iopub.status.idle":"2023-05-10T15:03:39.916814Z","shell.execute_reply":"2023-05-10T15:03:39.915804Z","shell.execute_reply.started":"2023-05-10T15:03:39.906254Z"},"trusted":true},"outputs":[],"source":["from skimage.transform import resize as resize_ski\n","import pathlib"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.918543Z","iopub.status.busy":"2023-05-10T15:03:39.918095Z","iopub.status.idle":"2023-05-10T15:03:39.929658Z","shell.execute_reply":"2023-05-10T15:03:39.928498Z","shell.execute_reply.started":"2023-05-10T15:03:39.918498Z"},"trusted":true},"outputs":[],"source":["def rle(predictions_map, threshold):\n","    flat_img = (np.where(predictions_map.flatten() >= threshold, 1, 0)).astype(np.uint8)\n","    \n","    # Add padding at the beginning and end\n","    flat_img = np.pad(flat_img, pad_width=1, mode='constant', constant_values=0)\n","\n","    starts = np.where((flat_img[:-1] == 0) & (flat_img[1:] == 1))[0]\n","    ends = np.where((flat_img[:-1] == 1) & (flat_img[1:] == 0))[0]\n","\n","    lengths = ends - starts\n","    \n","    print(lengths.shape)\n","\n","    return \" \".join(map(str, np.c_[starts, lengths].flatten()))\n"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.933503Z","iopub.status.busy":"2023-05-10T15:03:39.930806Z","iopub.status.idle":"2023-05-10T15:03:39.945903Z","shell.execute_reply":"2023-05-10T15:03:39.944714Z","shell.execute_reply.started":"2023-05-10T15:03:39.933458Z"},"trusted":true},"outputs":[],"source":["def update_submission(predictions_map, index):\n","    rle_ = rle(predictions_map, threshold=threshold)\n","    print(f\"{index},\" + rle_, file=open('submission.csv', 'a'))"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2023-05-10T15:03:39.948169Z","iopub.status.busy":"2023-05-10T15:03:39.947490Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Load data for test/a\n"]},{"name":"stderr","output_type":"stream","text":["17it [00:00, 34.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["34727 test locations (before filtering by mask)\n","22291 test locations (after filtering by mask)\n","test_volume.shape (4000, 9284, 17)\n","predictions_map.shape (9284, 4000, 1)\n","Compute predictions\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/349 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["subvolume after taking care of median and MAD [[[ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  ...\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]]\n","\n"," [[ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  ...\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]]\n","\n"," [[ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  ...\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]]\n","\n"," ...\n","\n"," [[ -1.4124719   -1.3697872   -1.3256538  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4023726   -1.3598034   -1.3165419  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.3927541   -1.3496659   -1.3066894  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  ...\n","  [  0.43403333   0.41179633   0.4095859  ...   0.1386578    0.779573\n","     0.15153338]\n","  [  0.41311318   0.40311804   0.4074376  ...   0.15640599   0.7830352\n","     0.14131089]\n","  [  0.38497916   0.38837263   0.40136307 ...   0.18912923   0.82919794\n","     0.16055322]]\n","\n"," [[ -0.8416961   -1.0874741   -1.2703164  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -0.71601474  -0.9625221   -1.1571227  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -0.5960244   -0.83680207  -1.0348173  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  ...\n","  [  0.40501764   0.42323938   0.4269205  ...   0.33610648   0.7224466\n","     0.24052916]\n","  [  0.3783264    0.40473083   0.41832727 ...   0.46589017   0.7085978\n","     0.23331329]\n","  [  0.34882975   0.3890638    0.40780798 ...   0.5929007    0.72821695\n","     0.24894768]]\n","\n"," [[ -0.13602117  -0.389371    -0.5544855  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -0.04608849  -0.29421702  -0.46003407 ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [  0.03927541  -0.19721988  -0.36150825 ... -12.398225   -12.942874\n","   -13.516537  ]\n","  ...\n","  [  0.373437     0.44812226   0.4479591  ...   0.47975597   0.6376226\n","     0.35898978]\n","  [  0.34562358   0.43222487   0.44188458 ...   0.61896837   0.6203116\n","     0.3066747 ]\n","  [  0.32149726   0.40941557   0.4338099  ...   0.74154186   0.62781304\n","     0.2892363 ]]]\n","subvolume after taking care of median and MAD [[[ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  ...\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]]\n","\n"," [[ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  ...\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]]\n","\n"," [[ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  ...\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]\n","  [ -1.4624078   -1.3945166   -1.3304689  ... -12.398225   -12.942874\n","   -13.516537  ]]\n","\n"," ...\n","\n"," [[  0.38489902   0.452807     0.5161123  ...   0.67886853   0.02596653\n","     0.04930848]\n","  [  0.3720744    0.4459719    0.5168531  ...   0.807543     0.09924985\n","    -0.01503307]\n","  [  0.35957038   0.4379848    0.515816   ...   0.94564617   0.18926717\n","    -0.08177991]\n","  ...\n","  [  0.33159667   0.33730128   0.3460997  ...   2.1497505    0.58742064\n","     0.26698738]\n","  [  0.3471465    0.34659398   0.35632268 ...   2.1087077    0.69244087\n","     0.20865905]\n","  [  0.36173454   0.35327548   0.36084154 ...   2.074875     0.73398733\n","     0.17197835]]\n","\n"," [[  0.41503686   0.4545734    0.51766795 ...   0.90682197   0.06924409\n","     0.18340349]\n","  [  0.40429625   0.45011905   0.52314985 ...   0.9805879    0.10040393\n","     0.10883944]\n","  [  0.39644116   0.44789186   0.52752054 ...   1.0343871    0.13675708\n","     0.03247144]\n","  ...\n","  [  0.31684834   0.34728515   0.32409808 ...   2.2368276    0.9284478\n","     0.20505111]\n","  [  0.33929145   0.35365948   0.34113637 ...   2.1591792    0.9815349\n","     0.2230908 ]\n","  [  0.35580313   0.35580984   0.34958145 ...   2.0953965    0.9959608\n","     0.2465424 ]]\n","\n"," [[  0.42986533   0.46386606   0.4966294  ...   1.0293955    0.1407963\n","     0.3307276 ]\n","  [  0.42529657   0.46632364   0.50900066 ...   1.0532446    0.11309867\n","     0.2705953 ]\n","  [  0.4264989    0.4753859    0.5205571  ...   1.031614     0.09117138\n","     0.20024052]\n","  ...\n","  [  0.29007694   0.36410415   0.3280984  ...   2.175818     0.9169071\n","     0.26217678]\n","  [  0.31652772   0.3680977    0.3432847  ...   2.0920687    0.99365264\n","     0.33493686]\n","  [  0.3315165    0.36364335   0.34809986 ...   2.0244038    1.0807848\n","     0.3860493 ]]]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 349/349 [00:20<00:00, 16.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["original predictions_map size (2727, 6330)\n","(60437,)\n","Load data for test/b\n"]},{"name":"stderr","output_type":"stream","text":["17it [00:01, 14.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["17182 test locations (before filtering by mask)\n","9490 test locations (after filtering by mask)\n","test_volume.shape (4000, 4642, 17)\n","predictions_map.shape (4642, 4000, 1)\n","Compute predictions\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/149 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["subvolume after taking care of median and MAD [[[ 0.9778992   1.0835056   1.0951998  ...  0.3371465   0.5083001\n","    0.30782428]\n","  [ 0.977232    1.0957428   1.0877805  ...  0.43946615  0.560425\n","    0.22683597]\n","  [ 0.9783162   1.084626    1.0616788  ...  0.48935494  0.6185259\n","    0.21791352]\n","  ...\n","  [ 0.6112756   1.1382282   1.9949048  ...  0.7632666   0.37084994\n","    0.74124914]\n","  [ 0.5971811   1.1811445   2.1259499  ...  0.7410232   0.45916334\n","    0.7793411 ]\n","  [ 0.5219549   1.1209066   2.040404   ...  0.7403877   0.5182603\n","    0.6523679 ]]\n","\n"," [[ 0.9101789   1.0254222   1.0193975  ...  0.3301557   0.5053121\n","    0.42381606]\n","  [ 0.91468245  1.0449845   1.0298561  ...  0.3463616   0.50365204\n","    0.38126287]\n","  [ 0.9331137   1.0543778   1.0403147  ...  0.4391484   0.5507968\n","    0.44269046]\n","  ...\n","  [ 0.5656561   0.68846947  2.003665   ...  0.7349857   0.14575033\n","    0.4327385 ]\n","  [ 0.56165296  0.69855225  2.0808082  ...  0.63266605  0.23207171\n","    0.53946465]\n","  [ 0.4905967   0.63848674  1.932511   ...  0.60851604  0.37250996\n","    0.59402883]]\n","\n"," [[ 0.96388805  1.02525     1.0180566  ...  0.5592628   0.4750996\n","    0.6094715 ]\n","  [ 0.9829865   1.0246466   1.0356663  ...  0.558945    0.5192563\n","    0.6050103 ]\n","  [ 0.9861557   1.0361944   1.0519353  ...  0.6895456   0.51095617\n","    0.6750172 ]\n","  ...\n","  [ 0.5471415   0.214495    1.3931348  ...  0.7565936   0.44754317\n","    0.3668497 ]\n","  [ 0.52862686  0.17830059  1.3714132  ...  0.79694945  0.500664\n","    0.6379547 ]\n","  [ 0.5312956   0.20932437  1.2369715  ...  0.77883697  0.5185923\n","    0.634523  ]]\n","\n"," ...\n","\n"," [[-1.         -1.         -1.         ... -6.897998   -7.2363877\n","   -7.5       ]\n","  [ 0.8491306   0.9701827   1.1102172  ...  0.15030187  0.70982736\n","    0.99004805]\n","  [ 0.85104877  0.9753533   1.0903728  ...  0.14394662  0.74601597\n","    1.0367193 ]\n","  ...\n","  [ 0.47516784  2.3003275   2.649057   ...  0.5815062   0.875166\n","    0.6952642 ]\n","  [ 0.47299945  2.3054118   2.664432   ...  0.39815697  0.7377158\n","    0.6949211 ]\n","  [ 0.74780035  2.372544    2.7138643  ...  0.39243725  0.689243\n","    0.7182567 ]]\n","\n"," [[-1.         -1.         -1.         ... -6.897998   -7.2363877\n","   -7.5       ]\n","  [ 0.79542136  1.0108583   1.0574775  ...  0.04258024  0.6613546\n","    1.0171585 ]\n","  [ 0.80276054  1.0170631   1.0560472  ...  0.03495393  0.62815404\n","    0.96842825]\n","  ...\n","  [ 0.23189192  1.9802654   2.5821936  ...  0.69018114  0.9940239\n","    0.49965683]\n","  [ 0.271173    2.089969    2.7322786  ...  0.81188434  1.0132802\n","    0.40253946]\n","  [ 0.41103375  2.1459842   2.9663897  ...  0.82109946  1.0478088\n","    0.19183253]]\n","\n"," [[ 0.3280514   0.44286454  0.45615447 ... -1.7464252  -1.4940239\n","   -1.3582704 ]\n","  [ 0.8281973   1.009221    0.9789935  ...  0.12392755  0.62217796\n","    0.9934797 ]\n","  [ 0.7905842   1.0511893   0.9890051  ...  0.09977756  0.64575034\n","    1.0408373 ]\n","  ...\n","  [ 0.38025936  2.3046362   2.6471798  ...  0.8179218   1.0737052\n","    0.09917639]\n","  [ 0.50018764  2.357032    2.8669884  ...  0.7235462   0.92397076\n","    0.1674674 ]\n","  [ 0.47967142  2.2984316   3.047734   ...  0.54591674  0.7400398\n","    0.21173644]]]\n","subvolume after taking care of median and MAD [[[ 0.8990034   0.873061    1.1123626  ...  0.4159517   0.45949537\n","    0.41352093]\n","  [ 0.9051749   0.90098244  1.1096809  ...  0.40451223  0.35358566\n","    0.4375429 ]\n","  [ 0.94445604  0.9394174   0.963976   ...  0.36574516  0.26460823\n","    0.3843514 ]\n","  ...\n","  [ 1.0574622   1.0886763   0.9553053  ...  0.41404513  0.41998672\n","    0.22923817]\n","  [ 1.0284392   1.1016029   0.9585233  ...  0.41213855  0.4495352\n","    0.24708305]\n","  [ 0.98281974  1.0756636   0.9924913  ...  0.38036224  0.49800798\n","    0.30370626]]\n","\n"," [[ 0.8464618   0.9086522   1.210691   ...  0.264061    0.34694555\n","    0.4622512 ]\n","  [ 0.8602227   0.9101172   1.1903102  ...  0.25166824  0.18459496\n","    0.38332188]\n","  [ 0.8659772   0.9313168   1.1435595  ...  0.27740705  0.20949535\n","    0.30782428]\n","  ...\n","  [ 1.0496227   0.99913824  0.91633147 ...  0.33555767  0.47078353\n","    0.17330131]\n","  [ 1.046787    1.058859    0.88960403 ...  0.39434382  0.43957505\n","    0.24365135]\n","  [ 0.994996    1.0684247   0.9055153  ...  0.485224    0.5285525\n","    0.38949898]]\n","\n"," [[ 0.8191068   0.962082    1.1692142  ...  0.08738481  0.18592298\n","    0.48318464]\n","  [ 0.82452774  0.9395898   1.174667   ...  0.13790911  0.18260293\n","    0.33047357]\n","  [ 0.7983404   0.9437263   1.1882542  ...  0.11566571  0.37250996\n","    0.13006178]\n","  ...\n","  [ 1.0172637   1.0206826   0.91043174 ...  0.29138863  0.36918992\n","    0.26046672]\n","  [ 1.0300238   1.0814375   0.8880844  ...  0.3438195   0.40438247\n","    0.46533975]\n","  [ 1.0225178   1.1060841   0.9292929  ...  0.37718463  0.28950864\n","    0.59951955]]\n","\n"," ...\n","\n"," [[-1.         -1.         -1.         ... -6.897998   -7.2363877\n","   -7.5       ]\n","  [-1.         -1.         -1.         ... -6.897998   -7.2363877\n","   -7.5       ]\n","  [-1.         -1.         -1.         ... -6.897998   -7.2363877\n","   -7.5       ]\n","  ...\n","  [ 0.9330303   0.9750948   1.1355144  ...  0.68382585  0.98306775\n","    0.91763896]\n","  [ 0.92469037  1.0049983   1.1505319  ...  0.78233236  1.0215803\n","    0.935827  ]\n","  [ 0.91476583  1.0297312   1.1570573  ...  0.8452494   1.0590969\n","    0.93342483]]\n","\n"," [[-1.         -1.         -1.         ... -6.897998   -7.2363877\n","   -7.5       ]\n","  [-1.         -1.         -1.         ... -6.897998   -7.2363877\n","   -7.5       ]\n","  [-1.         -1.         -1.         ... -6.897998   -7.2363877\n","   -7.5       ]\n","  ...\n","  [ 0.9376173   0.9943123   1.2027353  ...  0.7826502   0.86752987\n","    0.76012355]\n","  [ 0.9479588   0.98922783  1.1987128  ...  0.8722593   0.8286853\n","    0.8586136 ]\n","  [ 0.95304614  0.9992244   1.1977295  ...  0.9354941   0.813081\n","    0.8057653 ]]\n","\n"," [[-1.         -1.         -1.         ... -6.897998   -7.2363877\n","   -7.5       ]\n","  [-1.         -1.         -1.         ... -6.897998   -7.2363877\n","   -7.5       ]\n","  [-1.         -1.         -1.         ... -6.897998   -7.2363877\n","   -7.5       ]\n","  ...\n","  [ 0.9295275   1.0376594   1.1266649  ...  0.7931363   0.78021246\n","    0.63692516]\n","  [ 0.94754183  1.0395553   1.1287209  ...  0.9269145   0.811421\n","    0.6338366 ]\n","  [ 0.95137817  1.0304205   1.1430231  ...  1.0219257   0.9033865\n","    0.68702817]]]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 149/149 [00:09<00:00, 16.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["original predictions_map size (5454, 6330)\n","(539,)\n"]}],"source":["print(\"Id,Predicted\", file=open('submission.csv', 'w'))\n","kind = \"test\"\n","folder = pathlib.Path(DATA_DIR) / kind\n","threshold = 0.25\n","for p in list(folder.iterdir()):\n","    index = p.stem\n","    predictions_map = compute_predictions_map(split=kind, index=index)\n","    original_size = cv2.imread(DATA_DIR + f\"/{kind}/{index}/mask.png\", 0).shape[:2]\n","    # W, H, C → H, W, C\n","    predictions_map = predictions_map.transpose((1, 0, 2))    \n","    predictions_map = resize_ski(predictions_map, (original_size[0], original_size[1], 1)).squeeze(axis=-1)    \n","    print(\"original predictions_map size\", predictions_map.shape)    \n","    # H, W → W, H\n","    update_submission(predictions_map, index)\n","    plt.imsave(f\"{index}.png\", predictions_map, cmap=\"gray\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
