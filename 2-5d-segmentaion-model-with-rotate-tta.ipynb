{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## summary\n","\n","* 2.5d segmentation\n","    *  segmentation_models_pytorch \n","    *  Unet\n","* use only 6 slices\n","* slide inference\n","* add rotate TTA"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:02.136427Z","iopub.status.busy":"2023-05-09T12:35:02.136098Z","iopub.status.idle":"2023-05-09T12:35:09.784209Z","shell.execute_reply":"2023-05-09T12:35:09.783037Z","shell.execute_reply.started":"2023-05-09T12:35:02.136394Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from torch.cuda.amp import autocast, GradScaler\n","import sys\n","import time\n","import torch as tc\n","import random\n","from torch.utils.data import DataLoader, Dataset\n","import torch\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import numpy as np\n","\n","from tqdm.auto import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import AdamW\n","\n","from torch.utils.data import DataLoader, Dataset\n","import matplotlib.pyplot as plt\n","import cv2,gc\n","import os,warnings\n","import pandas as pd"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:09.787692Z","iopub.status.busy":"2023-05-09T12:35:09.78644Z","iopub.status.idle":"2023-05-09T12:35:13.714179Z","shell.execute_reply":"2023-05-09T12:35:13.712853Z","shell.execute_reply.started":"2023-05-09T12:35:09.787648Z"},"trusted":true},"outputs":[],"source":["# sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\n","# sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\n","# sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","# sys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models.pytorch-master')\n","\n","import segmentation_models_pytorch as smp"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## config"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:13.717364Z","iopub.status.busy":"2023-05-09T12:35:13.716501Z","iopub.status.idle":"2023-05-09T12:35:13.731346Z","shell.execute_reply":"2023-05-09T12:35:13.73002Z","shell.execute_reply.started":"2023-05-09T12:35:13.717323Z"},"trusted":true},"outputs":[],"source":["import os\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","class CFG:\n","    # ============== comp exp name =============\n","    comp_name = 'vesuvius'\n","\n","    comp_dir_path = './'\n","    # comp_dir_path = '/kaggle/input/'\n","    # comp_folder_name = 'vesuvius-challenge-ink-detection'\n","    comp_folder_name = ''\n","    # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n","    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n","    \n","    exp_name = 'vesuvius_2d_slide_exp001'\n","\n","    # ============== pred target =============\n","    target_size = 1\n","    TTA=True\n","    \n","    # ============== model cfg =============\n","    model_name = 'Unet'\n","    # backbone = 'efficientnet-b0'\n","    backbone = 'se_resnext50_32x4d'\n","\n","    in_chans = 6 # 65\n","    # ============== training cfg =============\n","    size = 224\n","    tile_size = 224\n","    stride = tile_size // 8\n","\n","    batch_size = 64 # 32\n","    use_amp = True\n","\n","    scheduler = 'GradualWarmupSchedulerV2'\n","    # scheduler = 'CosineAnnealingLR'\n","    epochs = 15\n","\n","    warmup_factor = 10\n","    lr = 1e-4 / warmup_factor\n","\n","    # ============== fold =============\n","    valid_id = 2\n","\n","    objective_cv = 'binary'  # 'binary', 'multiclass', 'regression'\n","    metric_direction = 'maximize'  # maximize, 'minimize'\n","    # metrics = 'dice_coef'\n","\n","    # ============== fixed =============\n","    pretrained = True\n","    inf_weight = 'best'  # 'best'\n","\n","    min_lr = 1e-6\n","    weight_decay = 1e-6\n","    max_grad_norm = 1000\n","\n","    print_freq = 50\n","    num_workers = 4\n","\n","    seed = 42\n","\n","    # ============== augmentation =============\n","    train_aug_list = [\n","        # A.RandomResizedCrop(\n","        #     size, size, scale=(0.85, 1.0)),\n","        A.Resize(size, size),\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        A.RandomBrightnessContrast(p=0.75),\n","        A.ShiftScaleRotate(p=0.75),\n","        A.OneOf([\n","                A.GaussNoise(var_limit=[10, 50]),\n","                A.GaussianBlur(),\n","                A.MotionBlur(),\n","                ], p=0.4),\n","        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n","        A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3), \n","                        mask_fill_value=0, p=0.5),\n","        # A.Cutout(max_h_size=int(size * 0.6),\n","        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n","        A.Normalize(\n","            mean= [0] * in_chans,\n","            std= [1] * in_chans\n","        ),\n","        ToTensorV2(transpose_mask=True),\n","    ]\n","\n","    valid_aug_list = [\n","        A.Resize(size, size),\n","        A.Normalize(\n","            mean= [0] * in_chans,\n","            std= [1] * in_chans\n","        ),\n","        ToTensorV2(transpose_mask=True),\n","    ]\n"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:13.73584Z","iopub.status.busy":"2023-05-09T12:35:13.735463Z","iopub.status.idle":"2023-05-09T12:35:13.747521Z","shell.execute_reply":"2023-05-09T12:35:13.746522Z","shell.execute_reply.started":"2023-05-09T12:35:13.735797Z"},"trusted":true},"outputs":[],"source":["IS_DEBUG = False\n","mode = 'train' if IS_DEBUG else 'test'\n","TH = 0.25"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:13.749965Z","iopub.status.busy":"2023-05-09T12:35:13.749053Z","iopub.status.idle":"2023-05-09T12:35:13.847618Z","shell.execute_reply":"2023-05-09T12:35:13.846519Z","shell.execute_reply.started":"2023-05-09T12:35:13.749867Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## helper"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:13.851933Z","iopub.status.busy":"2023-05-09T12:35:13.851494Z","iopub.status.idle":"2023-05-09T12:35:13.860836Z","shell.execute_reply":"2023-05-09T12:35:13.859766Z","shell.execute_reply.started":"2023-05-09T12:35:13.851898Z"},"trusted":true},"outputs":[],"source":["# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n","def rle(img):\n","    '''\n","    img: numpy array, 1 - mask, 0 - background\n","    Returns run length as string formated\n","    '''\n","    pixels = img.flatten()\n","    # pixels = (pixels >= thr).astype(int)\n","    \n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## dataset"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:13.863452Z","iopub.status.busy":"2023-05-09T12:35:13.862839Z","iopub.status.idle":"2023-05-09T12:35:13.87806Z","shell.execute_reply":"2023-05-09T12:35:13.877034Z","shell.execute_reply.started":"2023-05-09T12:35:13.863409Z"},"trusted":true},"outputs":[],"source":["def read_image(fragment_id):\n","    images = []\n","\n","    # idxs = range(65)\n","    mid = 65 // 2\n","    start = mid - CFG.in_chans // 2\n","    end = mid + CFG.in_chans // 2\n","    idxs = range(start, end)\n","\n","    for i in tqdm(idxs):\n","        \n","        image = cv2.imread(CFG.comp_dataset_path + f\"{mode}/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n","\n","        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n","        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size)\n","\n","        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n","\n","        images.append(image)\n","    images = np.stack(images, axis=2)\n","    \n","    return images"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:13.881861Z","iopub.status.busy":"2023-05-09T12:35:13.87948Z","iopub.status.idle":"2023-05-09T12:35:13.891631Z","shell.execute_reply":"2023-05-09T12:35:13.890659Z","shell.execute_reply.started":"2023-05-09T12:35:13.88181Z"},"trusted":true},"outputs":[],"source":["def get_transforms(data, cfg):\n","    if data == 'train':\n","        aug = A.Compose(cfg.train_aug_list)\n","    elif data == 'valid':\n","        aug = A.Compose(cfg.valid_aug_list)\n","\n","    # print(aug)\n","    return aug\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, images, cfg, labels=None, transform=None):\n","        self.images = images\n","        self.cfg = cfg\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        # return len(self.xyxys)\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        # x1, y1, x2, y2 = self.xyxys[idx]\n","        image = self.images[idx]\n","        data = self.transform(image=image)\n","        image = data['image']\n","        if self.labels:\n","            return image, self.labels\n","        return image, None\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def make_train_dataset(fragment_id):\n","    train_images = read_image(fragment_id)\n","    \n","    x1_list = list(range(0, train_images.shape[1]-CFG.tile_size+1, CFG.stride))\n","    y1_list = list(range(0, train_images.shape[0]-CFG.tile_size+1, CFG.stride))\n","    \n","    labels = cv2.imread(CFG.comp_dataset_path + f\"{mode}/{fragment_id}/inkables.png\", 0)\n","    labels = (labels / 255).astype(int)\n","    \n","    train_images_list = []\n","    xyxys = []\n","    for y1 in y1_list:\n","        for x1 in x1_list:\n","            y2 = y1 + CFG.tile_size\n","            x2 = x1 + CFG.tile_size\n","            \n","            train_images_list.append(train_images[y1:y2, x1:x2])\n","            xyxys.append((x1, y1, x2, y2))\n","    xyxys = np.stack(xyxys)\n","\n","    dataset = CustomDataset(\n","        train_images_list,\n","        CFG, \n","        labels=labels,\n","        transform=get_transforms(data='valid', cfg=CFG)\n","    )\n","    \n","    loader = DataLoader(\n","        dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers, pin_memory=True, drop_last=False\n","    )\n","    \n","    return loader, xyxys"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:13.894905Z","iopub.status.busy":"2023-05-09T12:35:13.894178Z","iopub.status.idle":"2023-05-09T12:35:13.904683Z","shell.execute_reply":"2023-05-09T12:35:13.90335Z","shell.execute_reply.started":"2023-05-09T12:35:13.894849Z"},"trusted":true},"outputs":[],"source":["def make_test_dataset(fragment_id):\n","    test_images = read_image(fragment_id)\n","    \n","    x1_list = list(range(0, test_images.shape[1]-CFG.tile_size+1, CFG.stride))\n","    y1_list = list(range(0, test_images.shape[0]-CFG.tile_size+1, CFG.stride))\n","    \n","    test_images_list = []\n","    xyxys = []\n","    for y1 in y1_list:\n","        for x1 in x1_list:\n","            y2 = y1 + CFG.tile_size\n","            x2 = x1 + CFG.tile_size\n","            \n","            test_images_list.append(test_images[y1:y2, x1:x2])\n","            xyxys.append((x1, y1, x2, y2))\n","    xyxys = np.stack(xyxys)\n","            \n","    test_dataset = CustomDataset(test_images_list, CFG, transform=get_transforms(data='valid', cfg=CFG))\n","    \n","    test_loader = DataLoader(test_dataset,\n","                          batch_size=CFG.batch_size,\n","                          shuffle=False,\n","                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","    \n","    return test_loader, xyxys"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## model"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:13.910401Z","iopub.status.busy":"2023-05-09T12:35:13.909996Z","iopub.status.idle":"2023-05-09T12:35:13.921196Z","shell.execute_reply":"2023-05-09T12:35:13.92008Z","shell.execute_reply.started":"2023-05-09T12:35:13.910356Z"},"trusted":true},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, weight=None):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        self.encoder = smp.Unet(\n","            encoder_name=cfg.backbone, \n","            encoder_weights=weight,\n","            in_channels=cfg.in_chans,\n","            classes=cfg.target_size,\n","            activation=None,\n","        )\n","\n","    def forward(self, image):\n","        output = self.encoder(image)\n","        output = output.squeeze(-1)\n","        return output\n","\n","def build_model(cfg, weight=\"imagenet\"):\n","    print('model_name', cfg.model_name)\n","    print('backbone', cfg.backbone)\n","\n","    model = CustomModel(cfg, weight)\n","    return model\n"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:13.923906Z","iopub.status.busy":"2023-05-09T12:35:13.92289Z","iopub.status.idle":"2023-05-09T12:35:13.934595Z","shell.execute_reply":"2023-05-09T12:35:13.933867Z","shell.execute_reply.started":"2023-05-09T12:35:13.923865Z"},"trusted":true},"outputs":[],"source":["class EnsembleModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.ModuleList()\n","        for fold in [1, 2, 3]:\n","            _model = build_model(CFG, weight=None)\n","            #_model.to(device)\n","\n","            os.makedirs(f\"{CFG.exp_name}/vesuvius-models/\", exist_ok=True)            \n","            model_path = f'{CFG.exp_name}/vesuvius-models/Unet_fold{fold}_best.pth'\n","            # model_path = f'/kaggle/input/vesuvius-models-public/{CFG.exp_name}/vesuvius-models/Unet_fold{fold}_best.pth'\n","            if os.path.exists(model_path):\n","                state = torch.load(model_path)['model']\n","                _model.load_state_dict(state)\n","            _model.eval()\n","\n","            self.model.append(_model)\n","    \n","    def forward(self,x):\n","        output=[]\n","        for m in self.model:\n","            output.append(m(x))\n","        output=torch.stack(output,dim=0).mean(0)\n","        return output\n","        \n","    "]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:13.937172Z","iopub.status.busy":"2023-05-09T12:35:13.936174Z","iopub.status.idle":"2023-05-09T12:35:13.949601Z","shell.execute_reply":"2023-05-09T12:35:13.94867Z","shell.execute_reply.started":"2023-05-09T12:35:13.937131Z"},"trusted":true},"outputs":[],"source":["def TTA(x:tc.Tensor,model:nn.Module):\n","    #x.shape=(batch,c,h,w)\n","    if CFG.TTA:\n","        shape=x.shape\n","        x=[x,*[tc.rot90(x,k=i,dims=(-2,-1)) for i in range(1,4)]]\n","        x=tc.cat(x,dim=0)\n","        x=model(x)\n","        x=torch.sigmoid(x)\n","        x=x.reshape(4,shape[0],*shape[2:])\n","        x=[tc.rot90(x[i],k=-i,dims=(-2,-1)) for i in range(4)]\n","        x=tc.stack(x,dim=0)\n","        return x.mean(0)\n","    else :\n","        x=model(x)\n","        x=torch.sigmoid(x)\n","        return x"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:35:13.952066Z","iopub.status.busy":"2023-05-09T12:35:13.951119Z","iopub.status.idle":"2023-05-09T12:35:57.01868Z","shell.execute_reply":"2023-05-09T12:35:57.01754Z","shell.execute_reply.started":"2023-05-09T12:35:13.952024Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model_name Unet\n","backbone se_resnext50_32x4d\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'vesuvius_2d_slide_exp001/vesuvius-models/Unet_fold1_best.pth'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/fummicc1/codes/competitions/kaggle-ink-detection/2-5d-segmentaion-model-with-rotate-tta.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.59/home/fummicc1/codes/competitions/kaggle-ink-detection/2-5d-segmentaion-model-with-rotate-tta.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.59/home/fummicc1/codes/competitions/kaggle-ink-detection/2-5d-segmentaion-model-with-rotate-tta.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     fragment_ids \u001b[39m=\u001b[39m [\u001b[39m3\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.59/home/fummicc1/codes/competitions/kaggle-ink-detection/2-5d-segmentaion-model-with-rotate-tta.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m EnsembleModel()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.59/home/fummicc1/codes/competitions/kaggle-ink-detection/2-5d-segmentaion-model-with-rotate-tta.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDataParallel(model, device_ids\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.59/home/fummicc1/codes/competitions/kaggle-ink-detection/2-5d-segmentaion-model-with-rotate-tta.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcuda()\n","\u001b[1;32m/home/fummicc1/codes/competitions/kaggle-ink-detection/2-5d-segmentaion-model-with-rotate-tta.ipynb Cell 18\u001b[0m in \u001b[0;36mEnsembleModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.59/home/fummicc1/codes/competitions/kaggle-ink-detection/2-5d-segmentaion-model-with-rotate-tta.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mCFG\u001b[39m.\u001b[39mexp_name\u001b[39m}\u001b[39;00m\u001b[39m/vesuvius-models/Unet_fold\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m_best.pth\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.59/home/fummicc1/codes/competitions/kaggle-ink-detection/2-5d-segmentaion-model-with-rotate-tta.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# model_path = f'/kaggle/input/vesuvius-models-public/{CFG.exp_name}/vesuvius-models/Unet_fold{fold}_best.pth'\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.59/home/fummicc1/codes/competitions/kaggle-ink-detection/2-5d-segmentaion-model-with-rotate-tta.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(model_path)[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.59/home/fummicc1/codes/competitions/kaggle-ink-detection/2-5d-segmentaion-model-with-rotate-tta.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m _model\u001b[39m.\u001b[39mload_state_dict(state)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.60.59/home/fummicc1/codes/competitions/kaggle-ink-detection/2-5d-segmentaion-model-with-rotate-tta.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m _model\u001b[39m.\u001b[39meval()\n","File \u001b[0;32m~/anaconda3/envs/ink-detection-3_8/lib/python3.8/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n","File \u001b[0;32m~/anaconda3/envs/ink-detection-3_8/lib/python3.8/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n","File \u001b[0;32m~/anaconda3/envs/ink-detection-3_8/lib/python3.8/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'vesuvius_2d_slide_exp001/vesuvius-models/Unet_fold1_best.pth'"]}],"source":["if mode == 'test':\n","    fragment_ids = sorted(os.listdir(CFG.comp_dataset_path + mode))\n","else:\n","    fragment_ids = [3]\n","model = EnsembleModel()\n","model = nn.DataParallel(model, device_ids=[0, 1])\n","model = model.cuda()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## main"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:37:26.903472Z","iopub.status.busy":"2023-05-09T12:37:26.902293Z","iopub.status.idle":"2023-05-09T13:21:49.817567Z","shell.execute_reply":"2023-05-09T13:21:49.816251Z","shell.execute_reply.started":"2023-05-09T12:37:26.90342Z"},"trusted":true},"outputs":[],"source":["results = []\n","for fragment_id in fragment_ids:\n","    \n","    if mode == \"test\":\n","        loader, xyxys = make_test_dataset(fragment_id)\n","    else:\n","        loader, xyxys = make_train_dataset(fragment_id)\n","    \n","    binary_mask = cv2.imread(CFG.comp_dataset_path + f\"{mode}/{fragment_id}/mask.png\", 0)\n","    binary_mask = (binary_mask / 255).astype(int)\n","    \n","    ori_h = binary_mask.shape[0]\n","    ori_w = binary_mask.shape[1]\n","    # mask = mask / 255\n","\n","    pad0 = (CFG.tile_size - binary_mask.shape[0] % CFG.tile_size)\n","    pad1 = (CFG.tile_size - binary_mask.shape[1] % CFG.tile_size)\n","\n","    binary_mask = np.pad(binary_mask, [(0, pad0), (0, pad1)], constant_values=0)\n","    \n","    mask_pred = np.zeros(binary_mask.shape)\n","    mask_count = np.zeros(binary_mask.shape)\n","\n","    for step, (images) in tqdm(enumerate(loader), total=len(loader)):\n","        images = images.cuda()\n","        batch_size = images.size(0)\n","\n","        with torch.no_grad():\n","            y_preds = TTA(images,model).cpu().numpy()\n","\n","        start_idx = step*CFG.batch_size\n","        end_idx = start_idx + batch_size\n","        for i, (x1, y1, x2, y2) in enumerate(xyxys[start_idx:end_idx]):\n","            mask_pred[y1:y2, x1:x2] += y_preds[i].reshape(mask_pred[y1:y2, x1:x2].shape)\n","            mask_count[y1:y2, x1:x2] += np.ones((CFG.tile_size, CFG.tile_size))\n","    \n","    \n","    print(f'mask_count_min: {mask_count.min()}')\n","    mask_pred /= mask_count\n","    \n","    fig, axes = plt.subplots(1, 3, figsize=(15, 8))\n","    axes[0].imshow(mask_count)\n","    axes[1].imshow(mask_pred.copy())\n","    \n","    \n","    \n","    mask_pred = mask_pred[:ori_h, :ori_w]\n","    binary_mask = binary_mask[:ori_h, :ori_w]\n","    \n","    mask_pred = (mask_pred >= TH).astype(int)\n","    mask_pred *= binary_mask\n","    axes[2].imshow(mask_pred)\n","    plt.show()\n","    \n","    inklabels_rle = rle(mask_pred)\n","    \n","    results.append((fragment_id, inklabels_rle))\n","    \n","\n","    del mask_pred, mask_count\n","    del loader\n","    \n","    gc.collect()\n","    torch.cuda.empty_cache()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:36:13.936923Z","iopub.status.idle":"2023-05-09T12:36:13.939211Z","shell.execute_reply":"2023-05-09T12:36:13.938917Z","shell.execute_reply.started":"2023-05-09T12:36:13.938883Z"},"trusted":true},"outputs":[],"source":["sub = pd.DataFrame(results, columns=['Id', 'Predicted'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:36:13.940979Z","iopub.status.idle":"2023-05-09T12:36:13.941916Z","shell.execute_reply":"2023-05-09T12:36:13.941636Z","shell.execute_reply.started":"2023-05-09T12:36:13.941596Z"},"trusted":true},"outputs":[],"source":["sub"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:36:13.943448Z","iopub.status.idle":"2023-05-09T12:36:13.944316Z","shell.execute_reply":"2023-05-09T12:36:13.944057Z","shell.execute_reply.started":"2023-05-09T12:36:13.944031Z"},"trusted":true},"outputs":[],"source":["sample_sub = pd.read_csv(CFG.comp_dataset_path + 'sample_submission.csv')\n","sample_sub = pd.merge(sample_sub[['Id']], sub, on='Id', how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:36:13.945896Z","iopub.status.idle":"2023-05-09T12:36:13.946812Z","shell.execute_reply":"2023-05-09T12:36:13.946517Z","shell.execute_reply.started":"2023-05-09T12:36:13.94649Z"},"trusted":true},"outputs":[],"source":["sample_sub"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:36:13.94848Z","iopub.status.idle":"2023-05-09T12:36:13.949391Z","shell.execute_reply":"2023-05-09T12:36:13.949147Z","shell.execute_reply.started":"2023-05-09T12:36:13.949119Z"},"trusted":true},"outputs":[],"source":["sample_sub.to_csv(\"submission.csv\", index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":4}
