{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Keras starter kit [full training set, UNet]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:10:40.298967Z","iopub.status.busy":"2023-03-18T23:10:40.298008Z","iopub.status.idle":"2023-03-18T23:10:49.514216Z","shell.execute_reply":"2023-03-18T23:10:49.513058Z","shell.execute_reply.started":"2023-03-18T23:10:40.298921Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","import glob\n","import time\n","import PIL.Image as Image\n","import matplotlib.pyplot as plt\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","import matplotlib.patches as patches\n","from tqdm import tqdm\n","import cv2\n","\n","# Data config\n","DATA_DIR = '/home/fummicc1/codes/competitions/kaggle-ink-detection'\n","BUFFER = 64  # Half-size of papyrus patches we'll use as model inputs\n","Z_DIM = 32  # Number of slices in the z direction. Max value is 64 - Z_START\n","Z_START = 16  # Offset of slices in the z direction\n","SHARED_HEIGHT = 2000  # Height to resize all papyrii\n","\n","# (x, y)\n","val_location = (600, 500)\n","val_zone_size = (2000, 1000)\n","\n","# Model config\n","BATCH_SIZE = 64\n","USE_MIXED_PRECISION = True\n","USE_JIT_COMPILE = False\n","\n","threshold = 0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:10:49.517657Z","iopub.status.busy":"2023-03-18T23:10:49.516568Z","iopub.status.idle":"2023-03-18T23:10:52.651975Z","shell.execute_reply":"2023-03-18T23:10:52.650919Z","shell.execute_reply.started":"2023-03-18T23:10:49.517615Z"},"trusted":true},"outputs":[],"source":["plt.imshow(Image.open(DATA_DIR + \"/train/1/ir.png\"), cmap=\"gray\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load up the training data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:10:52.653587Z","iopub.status.busy":"2023-03-18T23:10:52.653064Z","iopub.status.idle":"2023-03-18T23:10:57.915118Z","shell.execute_reply":"2023-03-18T23:10:57.914028Z","shell.execute_reply.started":"2023-03-18T23:10:52.653544Z"},"trusted":true},"outputs":[],"source":["def resize(img):\n","    current_height, current_width = img.shape    \n","    aspect_ratio = current_width / current_height\n","    new_width = int(SHARED_HEIGHT * aspect_ratio)\n","    new_size = (new_width, SHARED_HEIGHT)\n","    img = cv2.resize(img, new_size)\n","    return img\n","\n","def load_mask(split, index):\n","    img = cv2.imread(f\"{DATA_DIR}/{split}/{index}/mask.png\", 0) // 255\n","    img = resize(img)    \n","    return img\n","\n","\n","def load_labels(split, index):\n","    img = cv2.imread(f\"{DATA_DIR}/{split}/{index}/inklabels.png\", 0) // 255\n","    img = resize(img)\n","    return img\n","\n","\n","mask = load_mask(split=\"train\", index=1)\n","labels = load_labels(split=\"train\", index=1)\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2)\n","ax1.set_title(\"mask.png\")\n","ax1.imshow(mask, cmap='gray')\n","ax2.set_title(\"inklabels.png\")\n","ax2.imshow(labels, cmap='gray')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:10:57.922052Z","iopub.status.busy":"2023-03-18T23:10:57.921638Z","iopub.status.idle":"2023-03-18T23:11:00.615559Z","shell.execute_reply":"2023-03-18T23:11:00.614397Z","shell.execute_reply.started":"2023-03-18T23:10:57.922012Z"},"trusted":true},"outputs":[],"source":["mask_test_a = load_mask(split=\"test\", index=\"a\")\n","mask_test_b = load_mask(split=\"test\", index=\"b\")\n","\n","mask_train_1 = load_mask(split=\"train\", index=1)\n","labels_train_1 = load_labels(split=\"train\", index=1)\n","\n","mask_train_2 = load_mask(split=\"train\", index=2)\n","labels_train_2 = load_labels(split=\"train\", index=2)\n","\n","mask_train_3 = load_mask(split=\"train\", index=3)\n","labels_train_3 = load_labels(split=\"train\", index=3)\n","\n","print(f\"mask_test_a: {mask_test_a.shape}\")\n","print(f\"mask_test_b: {mask_test_b.shape}\")\n","print(\"-\")\n","print(f\"mask_train_1: {mask_train_1.shape}\")\n","print(f\"labels_train_1: {labels_train_1.shape}\")\n","print(\"-\")\n","print(f\"mask_train_2: {mask_train_2.shape}\")\n","print(f\"labels_train_2: {labels_train_2.shape}\")\n","print(\"-\")\n","print(f\"mask_train_3: {mask_train_3.shape}\")\n","print(f\"labels_train_3: {labels_train_3.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:11:00.619816Z","iopub.status.busy":"2023-03-18T23:11:00.619103Z","iopub.status.idle":"2023-03-18T23:11:02.849127Z","shell.execute_reply":"2023-03-18T23:11:02.847843Z","shell.execute_reply.started":"2023-03-18T23:11:00.619773Z"},"trusted":true},"outputs":[],"source":["fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n","\n","ax1.set_title(\"labels_train_1\")\n","ax1.imshow(labels_train_1, cmap='gray')\n","\n","ax2.set_title(\"labels_train_2\")\n","ax2.imshow(labels_train_2, cmap='gray')\n","\n","ax3.set_title(\"labels_train_3\")\n","ax3.imshow(labels_train_3, cmap='gray')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:11:02.854397Z","iopub.status.busy":"2023-03-18T23:11:02.85384Z","iopub.status.idle":"2023-03-18T23:11:02.867203Z","shell.execute_reply":"2023-03-18T23:11:02.866021Z","shell.execute_reply.started":"2023-03-18T23:11:02.854351Z"},"trusted":true},"outputs":[],"source":["def load_volume(split, index):\n","    # Load the 3d x-ray scan, one slice at a time\n","    z_slices_fnames = sorted(glob.glob(f\"{DATA_DIR}/{split}/{index}/surface_volume/*.tif\"))[Z_START:Z_START + Z_DIM]\n","    z_slices = []\n","    for z, filename in  tqdm(enumerate(z_slices_fnames)):\n","        img = cv2.imread(filename, -1)\n","        img = resize(img)\n","        z_slices.append(img)\n","    return np.stack(z_slices, axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:11:02.874585Z","iopub.status.busy":"2023-03-18T23:11:02.872191Z","iopub.status.idle":"2023-03-18T23:14:11.220165Z","shell.execute_reply":"2023-03-18T23:14:11.218002Z","shell.execute_reply.started":"2023-03-18T23:11:02.874541Z"},"trusted":true},"outputs":[],"source":["volume_train_1 = load_volume(split=\"train\", index=1)\n","print(f\"volume_train_1: {volume_train_1.shape}, {volume_train_1.dtype}\")\n","\n","volume_train_2 = load_volume(split=\"train\", index=2)\n","print(f\"volume_train_2: {volume_train_2.shape}, {volume_train_2.dtype}\")\n","\n","volume_train_3 = load_volume(split=\"train\", index=3)\n","print(f\"volume_train_3: {volume_train_3.shape}, {volume_train_3.dtype}\")\n","\n","volume = np.concatenate([volume_train_1, volume_train_2, volume_train_3], axis=1).astype(np.float16)\n","print(f\"total volume: {volume.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["del volume_train_1\n","del volume_train_2\n","del volume_train_3"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:14:11.222178Z","iopub.status.busy":"2023-03-18T23:14:11.221817Z","iopub.status.idle":"2023-03-18T23:14:11.231554Z","shell.execute_reply":"2023-03-18T23:14:11.230344Z","shell.execute_reply.started":"2023-03-18T23:14:11.222141Z"},"trusted":true},"outputs":[],"source":["labels = np.concatenate([labels_train_1, labels_train_2, labels_train_3], axis=1)\n","print(f\"labels: {labels.shape}, {labels.dtype}\")\n","\n","mask = np.concatenate([mask_train_1, mask_train_2, mask_train_3], axis=1)\n","print(f\"mask: {mask.shape}, {mask.dtype}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Free up memory\n","del labels_train_1\n","del labels_train_2\n","del labels_train_3\n","del mask_train_1\n","del mask_train_2\n","del mask_train_3"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Visualize the training data\n","\n","In this case, not very informative. But remember to always visualize what you're training on, as a sanity check!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:14:11.233579Z","iopub.status.busy":"2023-03-18T23:14:11.233103Z","iopub.status.idle":"2023-03-18T23:14:16.475332Z","shell.execute_reply":"2023-03-18T23:14:16.474429Z","shell.execute_reply.started":"2023-03-18T23:14:11.233541Z"},"trusted":true},"outputs":[],"source":["fig, axes = plt.subplots(1, 2, figsize=(15, 3))\n","for z, ax in enumerate(axes):\n","    ax.imshow(volume[:, :, z], cmap='gray')\n","    ax.set_xticks([]); ax.set_yticks([])\n","fig.tight_layout()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Selection a validation holdout area\n","\n","We set aside some fraction of the input to validate our model on."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:14:16.477954Z","iopub.status.busy":"2023-03-18T23:14:16.476814Z","iopub.status.idle":"2023-03-18T23:14:17.956818Z","shell.execute_reply":"2023-03-18T23:14:17.955681Z","shell.execute_reply.started":"2023-03-18T23:14:16.477911Z"},"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots()\n","ax.imshow(labels)\n","patch = patches.Rectangle([val_location[0], val_location[1]], val_zone_size[0], val_zone_size[1], linewidth=2, edgecolor='g', facecolor='none')\n","ax.add_patch(patch)\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Create a dataset that samples random locations in the input volume\n","\n","Our training dataset will grab random patches within the masked area and outside of the validation area."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:14:17.958942Z","iopub.status.busy":"2023-03-18T23:14:17.958495Z","iopub.status.idle":"2023-03-18T23:14:18.45515Z","shell.execute_reply":"2023-03-18T23:14:18.454126Z","shell.execute_reply.started":"2023-03-18T23:14:17.958902Z"},"trusted":true},"outputs":[],"source":["def sample_random_location(shape):\n","    random_train_x = np.random.random_integers(low=BUFFER, high=shape[0] - BUFFER - 1, size=())\n","    random_train_y = np.random.random_integers(low=BUFFER, high=shape[1] - BUFFER - 1, size=())\n","    random_train_location = np.stack([random_train_x, random_train_y], axis=0)\n","    return random_train_location\n","\n","\n","def is_in_masked_zone(location, mask):\n","    return mask[location[0], location[1]]\n","\n","sample_random_location_train = lambda x: sample_random_location(mask.shape)\n","is_in_mask_train = lambda x: is_in_masked_zone(x, mask)\n","\n","def is_in_val_zone(location, val_location, val_zone_size):\n","    x = location[0]\n","    y = location[1]\n","    x_match = val_location[0] - BUFFER <= x <= val_location[0] + val_zone_size[0] + BUFFER\n","    y_match = val_location[1] - BUFFER <= y <= val_location[1] + val_zone_size[1] + BUFFER\n","    return x_match and y_match\n","\n","def is_proper_train_location(location):\n","    return not is_in_val_zone(location, val_location, val_zone_size) and is_in_mask_train(location)\n","\n","# Create a list to store train locations\n","train_locations = []\n","\n","# Define the number of train locations you want to generate\n","num_train_locations = 10000\n","\n","# Generate train locations\n","while len(train_locations) < num_train_locations:\n","    location = sample_random_location_train(0)\n","    if is_proper_train_location(location):\n","        train_locations.append(location)\n","\n","# Convert the list of train locations to a PyTorch tensor\n","train_locations_ds = np.stack(train_locations, axis=0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Visualize some training patches\n","\n","Sanity check visually that our patches are where they should be."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:14:18.457083Z","iopub.status.busy":"2023-03-18T23:14:18.456727Z","iopub.status.idle":"2023-03-18T23:14:21.576187Z","shell.execute_reply":"2023-03-18T23:14:21.575222Z","shell.execute_reply.started":"2023-03-18T23:14:18.457045Z"},"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots()\n","ax.imshow(labels)\n","\n","# Define the number of samples you want to take from train_locations_ds\n","num_samples = 200\n","\n","# Iterate over the first 'num_samples' elements in train_locations_ds\n","for i in range(num_samples):\n","    x, y = train_locations_ds[i]\n","    patch = Rectangle([x - BUFFER, y - BUFFER], 2 * BUFFER, 2 * BUFFER, linewidth=2, edgecolor='r', facecolor='none')\n","    ax.add_patch(patch)\n","\n","val_patch = patches.Rectangle([val_location[0], val_location[1]], val_zone_size[0], val_zone_size[1], linewidth=2, edgecolor='g', facecolor='none')\n","ax.add_patch(val_patch)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from scipy.stats import median_abs_deviation\n","\n","\n","def extract_subvolume(location, volume):\n","    # print(np.unique(volume, return_counts=True, return_index=True))\n","    x = location[0]\n","    y = location[1]\n","    subvolume = volume[x-BUFFER:x+BUFFER, y-BUFFER:y+BUFFER, :] \n","    # print(\"subvolume[:, :, 0]\", subvolume[:, :, 0])\n","    median = np.median(subvolume, axis=2)\n","    MAD = median_abs_deviation(subvolume, axis=2)\n","    # print(\"median\", median)\n","    # print(\"MAD\", MAD)\n","    if np.all(MAD != 0):\n","        median = np.stack([median for i in range(Z_DIM)], axis=2)\n","        MAD = np.stack([MAD for i in range(Z_DIM)], axis=2)\n","        # print(\"mda.shape\", MDA.shape, \"MD\", MDA)\n","        subvolume = (subvolume.astype(np.float16) - median) / MAD\n","    else:\n","        print(\"Zero mad\")\n","        subvolume = subvolume.astype(np.float16) / 65536.\n","    return subvolume"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Create training dataset that yields random subvolumes and their labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import OneHotEncoder\n","\n","class SubvolumeDataset(Dataset):\n","    def __init__(self, locations, volume, labels, buffer, is_train: bool):\n","        self.locations = locations\n","        self.volume = volume\n","        self.labels = labels        \n","        self.buffer = buffer\n","        self.is_train = is_train\n","\n","    def __len__(self):\n","        return len(self.locations)\n","\n","    def __getitem__(self, idx):\n","        location = self.locations[idx]\n","        x, y = location[0], location[1]\n","\n","        subvolume = extract_subvolume(location, self.volume)        \n","        # print(\"subvolume\", subvolume)\n","        # print(\"labels\", labels)\n","        # subvolume = subvolume.numpy()\n","        subvolume = subvolume\n","        # print(subvolume)\n","        \n","        if self.is_train:            \n","            label = self.labels[x - self.buffer:x + self.buffer, y - self.buffer:y + self.buffer]    \n","            label = np.where(label == 1, 2 ** 16 - 1, 0).astype(np.uint16)\n","            # label = label.numpy()\n","            label = np.stack([label], axis=-1)\n","            # n_category = 2\n","            # label = np.eye(n_category)[label]\n","            \n","            # print(\"label\", label.dtype)\n","            # print(\"subvolume\", subvolume.dtype)            \n","            performed = A.Compose([            \n","                A.ToFloat(max_value=2**16-1),\n","                A.RandomBrightnessContrast(),\n","                A.HorizontalFlip(),\n","                A.VerticalFlip(),  \n","                A.FromFloat(max_value=2 ** 16-1),\n","            ])(image=subvolume, mask=label)          \n","            subvolume = performed[\"image\"]\n","            label = performed[\"mask\"]\n","            # print(\"label\", label.dtype)\n","            # print(\"subvolume\", subvolume.dtype)\n","            # →C, H, W\n","            subvolume = torch.from_numpy(subvolume.transpose(2, 0, 1).astype(np.float16))\n","            # print(performed)\n","            # print(subvolume.shape, label.shape)\n","            # H, W, C → C, H, W\n","            label = torch.from_numpy(label.transpose(2, 0, 1).astype(np.uint8) // 255) \n","        else:\n","            subvolume = torch.from_numpy(subvolume.transpose(2, 0, 1).astype(np.float16))\n","            label = None\n","        return subvolume, label\n","\n","# Convert train_locations_ds to a PyTorch tensor\n","train_locations_tensor = np.stack([x for x in train_locations_ds], axis=0)\n","\n","# Create an instance of the SubvolumeDataset\n","train_ds = SubvolumeDataset(train_locations_tensor, volume, labels, BUFFER, is_train=True)\n","\n","# Create a DataLoader with the dataset\n","train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:14:23.607564Z","iopub.status.busy":"2023-03-18T23:14:23.607154Z","iopub.status.idle":"2023-03-18T23:14:26.453345Z","shell.execute_reply":"2023-03-18T23:14:26.452345Z","shell.execute_reply.started":"2023-03-18T23:14:23.607531Z"},"trusted":true},"outputs":[],"source":["subvolume_batch, label_batch = train_ds[1]\n","print(f\"subvolume shape: {subvolume_batch.shape}\")\n","print(f\"label_batch shape: {label_batch.shape}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Check dataset throughput\n","\n","It's always a good idea to check that your data pipeline is efficient. You don't want to be CPU-bound at training time!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:14:26.45912Z","iopub.status.busy":"2023-03-18T23:14:26.455968Z","iopub.status.idle":"2023-03-18T23:14:31.187401Z","shell.execute_reply":"2023-03-18T23:14:31.186334Z","shell.execute_reply.started":"2023-03-18T23:14:26.459076Z"},"trusted":true},"outputs":[],"source":["# t0 = time.time()\n","# n = 200\n","# for _ in train_ds:\n","#     pass\n","# print(f\"Time per batch: {(time.time() - t0) / n:.4f}s\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Create validation dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:14:31.189186Z","iopub.status.busy":"2023-03-18T23:14:31.188813Z","iopub.status.idle":"2023-03-18T23:14:31.263309Z","shell.execute_reply":"2023-03-18T23:14:31.262192Z","shell.execute_reply.started":"2023-03-18T23:14:31.189143Z"},"trusted":true},"outputs":[],"source":["val_locations_stride = BUFFER\n","val_locations = []\n","for x in range(val_location[0], val_location[0] + val_zone_size[0], val_locations_stride):\n","    for y in range(val_location[1], val_location[1] + val_zone_size[1], val_locations_stride):\n","        val_locations.append((x, y))\n","\n","# Convert the list of val locations to a PyTorch tensor\n","val_locations_ds = np.stack(val_locations, axis=0)\n","\n","# Create an instance of the SubvolumeDataset\n","val_ds = SubvolumeDataset(val_locations_ds, volume, labels, BUFFER, is_train=True)\n","\n","# Create a DataLoader with the dataset\n","val_dataloader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Visualize validation dataset patches\n","\n","Note that they are partially overlapping, since the stride is half the patch size."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:14:31.265448Z","iopub.status.busy":"2023-03-18T23:14:31.264916Z","iopub.status.idle":"2023-03-18T23:14:35.752995Z","shell.execute_reply":"2023-03-18T23:14:35.751869Z","shell.execute_reply.started":"2023-03-18T23:14:31.265399Z"},"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots()\n","ax.imshow(labels)\n","\n","for x, y in val_locations_ds:\n","    patch = patches.Rectangle([x - BUFFER, y - BUFFER], 2 * BUFFER, 2 * BUFFER, linewidth=2, edgecolor='g', facecolor='none')\n","    ax.add_patch(patch)\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Compute a trivial baseline\n","\n","This is the highest validation score you can reach without looking at the inputs.\n","The model can be considered to have statistical power only if it can beat this baseline."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:14:35.755036Z","iopub.status.busy":"2023-03-18T23:14:35.754646Z","iopub.status.idle":"2023-03-18T23:14:38.733818Z","shell.execute_reply":"2023-03-18T23:14:38.73285Z","shell.execute_reply.started":"2023-03-18T23:14:35.754998Z"},"trusted":true},"outputs":[],"source":["def trivial_baseline(dataset):\n","    total = 0\n","    matches = 0.\n","    for _, batch_label in tqdm(dataset):\n","        batch_label = torch.tensor(batch_label)\n","        matches += torch.sum(batch_label.float())\n","        total += torch.numel(batch_label)\n","    return 1. - matches / total\n","\n","score = trivial_baseline(val_ds).item()\n","print(f\"Best validation score achievable trivially: {score * 100:.2f}% accuracy\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Augment the training data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Train a Keras model\n","\n","This model is a U-Net taken from [this segmentation tutorial](https://keras.io/examples/vision/oxford_pets_image_segmentation/).\n","\n","`model.fit()` goes brrrrr\n","\n","Conceptually it looks like this (animation from [this tutorial](https://www.kaggle.com/code/jpposma/vesuvius-challenge-ink-detection-tutorial)):\n","\n","![animation](https://user-images.githubusercontent.com/22727759/224853385-ed190d89-f466-469c-82a9-499881759d57.gif)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchmetrics import Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","class UNet(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UNet, self).__init__()\n","\n","        def conv_block(in_channels, out_channels):\n","            return nn.Sequential(\n","                nn.LeakyReLU(),\n","                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(out_channels),\n","            )\n","\n","        def transpose_conv_block(in_channels, out_channels):\n","            return nn.Sequential(\n","                nn.LeakyReLU(),\n","                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(out_channels),\n","            )\n","\n","        self.encoder = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv2d(in_channels if i == 2 else 64 * 2**(i - 1), 64 * 2**i, kernel_size=3, stride=2, padding=1),\n","                nn.BatchNorm2d(64 * 2**i),\n","                nn.LeakyReLU(),\n","                nn.Conv2d(64 * 2**i, 64 * 2**i, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(64 * 2**i),\n","                nn.LeakyReLU(),\n","            )\n","            for i in range(2, 4)\n","        ])\n","\n","\n","        self.middle = nn.Sequential(\n","            conv_block(512, 512),\n","            conv_block(512, 512),\n","        )\n","        \n","        self.decoder = nn.ModuleList([\n","            nn.Sequential(\n","                transpose_conv_block(2 ** (i + 7), 2 ** (i + 6)),\n","                transpose_conv_block(2 ** (i + 6), 2 ** (i + 5)),\n","                nn.Upsample(scale_factor=2, mode=\"nearest\"),\n","            )\n","            for i in range(3, 1, -1)\n","        ])\n","        self.final_decoder = nn.Sequential(\n","            nn.Conv2d(128, 32, kernel_size=3, padding=1),\n","            nn.Conv2d(32, out_channels, kernel_size=3, padding=1),\n","        )        \n","\n","    def forward(self, x):\n","        skip_connections = []\n","        for layer in self.encoder:\n","            x = layer(x)\n","            skip_connections.append(x)\n","\n","        x = self.middle(x)\n","        \n","        # print(\"encoder ok\", x.shape)\n","        for i, layer in enumerate(self.decoder):            \n","            # print(f\"decoder will {i}: ok\", x.shape)\n","            x = torch.cat([x, skip_connections[-i-1]], dim=1)  # Concatenate along channel dimension\n","            # print(f\"decoder with skip connection {i}: ok\", x.shape)            \n","            x = layer(x)            \n","            # print(f\"decoder {i}: ok\", x.shape)\n","        # print(\"decoder ok\")\n","        x = self.final_decoder(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:14:39.034124Z","iopub.status.busy":"2023-03-18T23:14:39.033748Z","iopub.status.idle":"2023-03-18T23:28:08.685364Z","shell.execute_reply":"2023-03-18T23:28:08.684324Z","shell.execute_reply.started":"2023-03-18T23:14:39.034086Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","# Define the model\n","model = UNet(Z_DIM, 1)\n","model = nn.DataParallel(model)\n","\n","if os.path.exists(f\"{DATA_DIR}/model.pt\"):\n","    # model.load_state_dict(torch.load(f\"{DATA_DIR}/model.pt\"))\n","    pass\n","\n","# Mixed precision training\n","scaler = torch.cuda.amp.GradScaler(enabled=USE_MIXED_PRECISION)\n","\n","# Loss, optimizer, and metric\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=5e-5)\n","\n","# Training loop\n","num_epochs = 20\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","accuracy = Accuracy(task=\"binary\").to(device)"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / medianZero mad / median\n","\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/20 [00:14<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[125], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m      4\u001b[0m running_accuracy \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfor\u001b[39;00m idx, (subvolumes, labels) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(train_dataloader), leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m      7\u001b[0m     subvolumes, labels \u001b[39m=\u001b[39m subvolumes\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)        \n\u001b[1;32m      8\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mfloat()        \n","File \u001b[0;32m~/anaconda3/envs/ink-detection/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/ink-detection/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/anaconda3/envs/ink-detection/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1330\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/ink-detection/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1296\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n","File \u001b[0;32m~/anaconda3/envs/ink-detection/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1134\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/ink-detection/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n","File \u001b[0;32m~/anaconda3/envs/ink-detection/lib/python3.11/multiprocessing/connection.py:256\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 256\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n","File \u001b[0;32m~/anaconda3/envs/ink-detection/lib/python3.11/multiprocessing/connection.py:423\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 423\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n","File \u001b[0;32m~/anaconda3/envs/ink-detection/lib/python3.11/multiprocessing/connection.py:930\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    927\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    929\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 930\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    931\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    932\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n","File \u001b[0;32m~/anaconda3/envs/ink-detection/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selector\u001b[39m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / medianZero mad / median\n","\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / medianZero mad / median\n","\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / medianZero mad / median\n","\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n","Zero mad / median\n"]}],"source":["for epoch in tqdm(range(num_epochs)):\n","    model.train()\n","    running_loss = 0.0\n","    running_accuracy = 0.0\n","\n","    for idx, (subvolumes, labels) in tqdm(enumerate(train_dataloader), leave=False):\n","        subvolumes, labels = subvolumes.to(device), labels.to(device)        \n","        labels = labels.float()        \n","\n","        optimizer.zero_grad()\n","\n","        with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION):            \n","            outputs = model(subvolumes)                 \n","            loss = criterion(outputs, labels)\n","            acc = accuracy(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item()\n","        running_accuracy += acc\n","        \n","    running_loss /= len(train_dataloader)\n","    running_accuracy /= len(train_dataloader)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    val_accuracy = 0.0\n","    with torch.no_grad():\n","        for subvolumes, labels in tqdm(val_dataloader, leave=False):\n","            subvolumes, labels = subvolumes.to(device), labels.to(device)\n","            labels = labels.float()\n","            outputs = model(subvolumes)\n","            loss = criterion(outputs, labels)\n","            acc = accuracy(outputs, labels)\n","\n","            val_loss += loss.item()\n","            val_accuracy += acc    \n","\n","    val_loss /= len(val_dataloader)\n","    val_accuracy /= len(val_dataloader)\n","\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}] Loss: {running_loss:.4f} Accuracy: {running_accuracy:.4f} Val_Loss: {val_loss:.4f} Val_Accuracy: {val_accuracy:.4f}\")\n","\n","    running_loss = 0.0\n","    running_accuracy = 0.0\n","    model.train()\n","\n","torch.save(model.state_dict(), \"model.pt\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Clear up memory"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["del volume\n","del mask\n","del labels\n","del train_ds\n","del val_ds\n","\n","import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:28:08.687464Z","iopub.status.busy":"2023-03-18T23:28:08.687065Z","iopub.status.idle":"2023-03-18T23:28:09.709853Z","shell.execute_reply":"2023-03-18T23:28:09.708782Z","shell.execute_reply.started":"2023-03-18T23:28:08.687423Z"},"trusted":true},"outputs":[],"source":["model = UNet(Z_DIM, 1)\n","model = nn.DataParallel(model)\n","model.load_state_dict(torch.load(\"model.pt\"))\n","model = model.to(device)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Compute predictions on test data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:28:09.711867Z","iopub.status.busy":"2023-03-18T23:28:09.711493Z","iopub.status.idle":"2023-03-18T23:28:09.724755Z","shell.execute_reply":"2023-03-18T23:28:09.723509Z","shell.execute_reply.started":"2023-03-18T23:28:09.711827Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from tqdm import tqdm\n","\n","def compute_predictions_map(split, index):\n","    print(f\"Load data for {split}/{index}\")\n","\n","    test_volume = load_volume(split=split, index=index)\n","    test_mask = load_mask(split=split, index=index)\n","\n","    test_locations = []\n","    stride = BUFFER // 2\n","    for x in range(BUFFER, test_volume.shape[0] - BUFFER, stride):\n","        for y in range(BUFFER, test_volume.shape[1] - BUFFER, stride):\n","            test_locations.append((x, y))\n","\n","    print(f\"{len(test_locations)} test locations (before filtering by mask)\")\n","\n","    # filter locations inside the mask\n","    test_locations = [loc for loc in test_locations if is_in_masked_zone(loc, test_mask)]\n","\n","    class TestDataset(Dataset):\n","        def __init__(self, test_locations, test_volume):\n","            self.test_locations = test_locations\n","            self.test_volume = test_volume\n","\n","        def __len__(self):\n","            return len(self.test_locations)\n","\n","        def __getitem__(self, idx):\n","            location = torch.tensor(self.test_locations[idx])\n","            subvolume = extract_subvolume(location, self.test_volume)\n","            subvolume = subvolume.astype(np.float16)\n","            subvolume = subvolume.transpose((2, 0, 1))\n","            return location, subvolume\n","\n","    test_ds = TestDataset(test_locations, test_volume)\n","    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n","\n","    predictions_map = np.zeros(test_volume.shape[:2] + (1,), dtype=np.float16)\n","    predictions_map_counts = np.zeros(test_volume.shape[:2] + (1,), dtype=np.float16)\n","\n","    print(f\"Compute predictions\")\n","\n","    model.eval()  # set model to evaluation mode\n","    with torch.no_grad():\n","        for loc_batch, patch_batch in tqdm(test_loader):\n","            loc_batch = loc_batch.to(device)\n","            patch_batch = patch_batch.to(device)\n","            predictions = model(patch_batch)            \n","            predictions = nn.Sigmoid()(predictions)\n","            predictions = torch.permute(predictions, (0, 2, 3, 1))\n","            predictions = predictions.cpu().numpy()  # move predictions to cpu and convert to numpy\n","            for (x, y), pred in zip(loc_batch, predictions):\n","                predictions_map[x - BUFFER : x + BUFFER, y - BUFFER : y + BUFFER, :] += pred\n","                predictions_map_counts[x - BUFFER : x + BUFFER, y - BUFFER : y + BUFFER, :] += 1\n","    predictions_map /= (predictions_map_counts + 1e-7)\n","    return predictions_map\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from skimage.transform import resize as resize_ski\n","import pathlib"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:28:09.727518Z","iopub.status.busy":"2023-03-18T23:28:09.726481Z","iopub.status.idle":"2023-03-18T23:35:39.938224Z","shell.execute_reply":"2023-03-18T23:35:39.937169Z","shell.execute_reply.started":"2023-03-18T23:28:09.727465Z"},"trusted":true},"outputs":[],"source":["def rle(predictions_map, threshold):\n","    flat_img = (np.where(predictions_map.flatten() > threshold, 1, 0)).astype(np.uint8)\n","\n","    starts = np.where((flat_img[:-1] == 0) & (flat_img[1:] == 1))[0] + 2\n","    ends = np.where((flat_img[:-1] == 1) & (flat_img[1:] == 0))[0] + 2\n","\n","    lengths = ends - starts\n","\n","    return \" \".join(map(str, np.c_[starts, lengths].flatten()))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Id,Predicted\", file=open('submission.csv', 'w'))\n","\n","def update_submission(predictions_map, index):\n","    rle_ = rle(predictions_map, threshold=threshold)\n","    print(f\"{index},\" + rle_, file=open('submission.csv', 'a'))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Resize prediction maps to their original size (for submission)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T23:35:44.578704Z","iopub.status.busy":"2023-03-18T23:35:44.578139Z","iopub.status.idle":"2023-03-18T23:35:49.82279Z","shell.execute_reply":"2023-03-18T23:35:49.821723Z","shell.execute_reply.started":"2023-03-18T23:35:44.578662Z"},"trusted":true},"outputs":[],"source":["folder = pathlib.Path(DATA_DIR) / \"test\"\n","for p in folder.iterdir():\n","    index = p.stem\n","    predictions_map = compute_predictions_map(split=\"test\", index=index)\n","    original_size = cv2.imread(DATA_DIR + f\"/test/{index}/mask.png\", 0).sha@e[:2]\n","    predictions_map = resize_ski(predictions_map, (original_size[0], original_size[1])).squeeze()\n","    update_submission(predictions_map, index)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
