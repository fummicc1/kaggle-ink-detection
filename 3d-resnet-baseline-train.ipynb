{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Introduction\n","This notebook is based on \n","1. [2.5d segmentaion baseline [training]](https://www.kaggle.com/code/tanakar/2-5d-segmentaion-baseline-training)\n","2. [2.5d segmentaion baseline [inference]](https://www.kaggle.com/code/tanakar/2-5d-segmentaion-baseline-inference)\n","3. [Vesuvius Challenge - 3D ResNet Training](https://www.kaggle.com/code/samfc10/vesuvius-challenge-3d-resnet-training)\n","4. [Improving performance with L1/Hessian denoising](https://www.kaggle.com/code/brettolsen/improving-performance-with-l1-hessian-denoising)\n","\n","Thank them for letting us learn more.(^w^)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Base parameter:\n","1. ResNet34\n","2. 1fold only!! (Use 2,3 to train and 1 to val)\n","3. use 16 channels\n","4. loss = 0.5 * BCELoss + 0.5 * DiceLoss\n","\n","then get cv0.55 (^w^)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T05:05:37.802699Z","iopub.status.busy":"2023-05-18T05:05:37.802266Z","iopub.status.idle":"2023-05-18T05:05:37.811251Z","shell.execute_reply":"2023-05-18T05:05:37.809786Z","shell.execute_reply.started":"2023-05-18T05:05:37.802657Z"},"trusted":true},"outputs":[],"source":["import os,cv2\n","import gc\n","import sys\n","import random\n","from glob import glob\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.cuda import amp\n","from torch.utils.data import Dataset, DataLoader\n","import segmentation_models_pytorch as smp\n","\n","ROOT_DIR = \"/home/fummicc1/codes/Kaggle/kaggle-ink-detection\"\n","\n","sys.path.append(ROOT_DIR)\n","# sys.path.append(\"/kaggle/input/resnet3d\")\n","from resnet3d import generate_model\n","import torch as tc"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T05:05:37.814777Z","iopub.status.busy":"2023-05-18T05:05:37.813627Z","iopub.status.idle":"2023-05-18T05:05:37.82481Z","shell.execute_reply":"2023-05-18T05:05:37.823645Z","shell.execute_reply.started":"2023-05-18T05:05:37.814737Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","    # ============== comp exp name =============\n","    comp_name = 'vesuvius'\n","\n","    comp_dir_path = '/home/fummicc1/codes/Kaggle/kaggle-ink-detection/'\n","    # comp_dir_path = '/kaggle/input/'\n","    comp_folder_name = ''\n","    # comp_folder_name = 'vesuvius-challenge-ink-detection'\n","    # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n","    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n","    \n","    exp_name = 'vesuvius_2d_slide_exp002'\n","\n","    # ============== pred target =============\n","    target_size = 1\n","\n","    # ============== model cfg =============\n","    model_name = 'Unet'\n","    #backbone = 'efficientnet-b5'\n","    #backbone = 'mit_b5'\n","    backbone = 'resnet3d'\n","    #backbone = 'resnext50_32x4d'\n","    pretrained = True\n","\n","    in_chans = 16 # 65\n","    load_chans=16\n","    # ============== training cfg =============\n","    prd_size=192\n","    stride = prd_size // 8\n","\n","    batch_size = 64 # 32\n","    use_amp = True\n","\n","    seed = 42\n","    num_workers=8\n","    \n","    mode = \"train\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## helper"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T05:05:37.827281Z","iopub.status.busy":"2023-05-18T05:05:37.826465Z","iopub.status.idle":"2023-05-18T05:05:37.841307Z","shell.execute_reply":"2023-05-18T05:05:37.840253Z","shell.execute_reply.started":"2023-05-18T05:05:37.827238Z"},"trusted":true},"outputs":[],"source":["# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n","def rle(img):\n","    '''\n","    img: numpy array, 1 - mask, 0 - background\n","    Returns run length as string formated\n","    '''\n","    pixels = img.flatten()\n","    # pixels = (pixels >= thr).astype(int)\n","    \n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)\n","def normalization(x:tc.Tensor)->tc.Tensor:\n","    \"\"\"input.shape=(batch,f1,f2,...)\"\"\"\n","    #[batch,f1,f2]->dim[1,2]\n","    dim=list(range(1,x.ndim))\n","    mean=x.mean(dim=dim,keepdim=True)\n","    std=x.std(dim=dim,keepdim=True)\n","    return (x-mean)/(std+1e-9)\n","\n","def get_folder_size(folder_path):\n","    total_size = 0\n","    for dirpath, dirnames, filenames in os.walk(folder_path):\n","        for f in filenames:\n","            fp = os.path.join(dirpath, f)\n","            total_size += os.path.getsize(fp)\n","    return total_size"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## L1/Hessian denoising"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T05:05:37.846035Z","iopub.status.busy":"2023-05-18T05:05:37.845657Z","iopub.status.idle":"2023-05-18T05:05:37.883804Z","shell.execute_reply":"2023-05-18T05:05:37.882552Z","shell.execute_reply.started":"2023-05-18T05:05:37.846004Z"},"trusted":true},"outputs":[],"source":["# import cupy as cp\n","# xp = cp\n","\n","# delta_lookup = {\n","#     \"xx\": xp.array([[1, -2, 1]], dtype=float),\n","#     \"yy\": xp.array([[1], [-2], [1]], dtype=float),\n","#     \"xy\": xp.array([[1, -1], [-1, 1]], dtype=float),\n","# }\n","\n","# def operate_derivative(img_shape, pair):\n","#     assert len(img_shape) == 2\n","#     delta = delta_lookup[pair]\n","#     fft = xp.fft.fftn(delta, img_shape)\n","#     return fft * xp.conj(fft)\n","\n","# def soft_threshold(vector, threshold):\n","#     return xp.sign(vector) * xp.maximum(xp.abs(vector) - threshold, 0)\n","\n","# def back_diff(input_image, dim):\n","#     assert dim in (0, 1)\n","#     r, n = xp.shape(input_image)\n","#     size = xp.array((r, n))\n","#     position = xp.zeros(2, dtype=int)\n","#     temp1 = xp.zeros((r+1, n+1), dtype=float)\n","#     temp2 = xp.zeros((r+1, n+1), dtype=float)\n","    \n","#     temp1[position[0]:size[0], position[1]:size[1]] = input_image\n","#     temp2[position[0]:size[0], position[1]:size[1]] = input_image\n","    \n","#     size[dim] += 1\n","#     position[dim] += 1\n","#     temp2[position[0]:size[0], position[1]:size[1]] = input_image\n","#     temp1 -= temp2\n","#     size[dim] -= 1\n","#     return temp1[0:size[0], 0:size[1]]\n","\n","# def forward_diff(input_image, dim):\n","#     assert dim in (0, 1)\n","#     r, n = xp.shape(input_image)\n","#     size = xp.array((r, n))\n","#     position = xp.zeros(2, dtype=int)\n","#     temp1 = xp.zeros((r+1, n+1), dtype=float)\n","#     temp2 = xp.zeros((r+1, n+1), dtype=float)\n","        \n","#     size[dim] += 1\n","#     position[dim] += 1\n","\n","#     temp1[position[0]:size[0], position[1]:size[1]] = input_image\n","#     temp2[position[0]:size[0], position[1]:size[1]] = input_image\n","    \n","#     size[dim] -= 1\n","#     temp2[0:size[0], 0:size[1]] = input_image\n","#     temp1 -= temp2\n","#     size[dim] += 1\n","#     return -temp1[position[0]:size[0], position[1]:size[1]]\n","\n","# def iter_deriv(input_image, b, scale, mu, dim1, dim2):\n","#     g = back_diff(forward_diff(input_image, dim1), dim2)\n","#     d = soft_threshold(g + b, 1 / mu)\n","#     b = b + (g - d)\n","#     L = scale * back_diff(forward_diff(d - b, dim2), dim1)\n","#     return L, b\n","\n","# def iter_xx(*args):\n","#     return iter_deriv(*args, dim1=1, dim2=1)\n","\n","# def iter_yy(*args):\n","#     return iter_deriv(*args, dim1=0, dim2=0)\n","\n","# def iter_xy(*args):\n","#     return iter_deriv(*args, dim1=0, dim2=1)\n","\n","# def iter_sparse(input_image, bsparse, scale, mu):\n","#     d = soft_threshold(input_image + bsparse, 1 / mu)\n","#     bsparse = bsparse + (input_image - d)\n","#     Lsparse = scale * (d - bsparse)\n","#     return Lsparse, bsparse\n","\n","# def denoise_image(input_image, iter_num=100, fidelity=150, sparsity_scale=10, continuity_scale=0.5, mu=1):\n","#     image_size = xp.shape(input_image)\n","#     #print(\"Initialize denoising\")\n","#     norm_array = (\n","#         operate_derivative(image_size, \"xx\") + \n","#         operate_derivative(image_size, \"yy\") + \n","#         2 * operate_derivative(image_size, \"xy\")\n","#     )\n","#     norm_array += (fidelity / mu) + sparsity_scale ** 2\n","#     b_arrays = {\n","#         \"xx\": xp.zeros(image_size, dtype=float),\n","#         \"yy\": xp.zeros(image_size, dtype=float),\n","#         \"xy\": xp.zeros(image_size, dtype=float),\n","#         \"L1\": xp.zeros(image_size, dtype=float),\n","#     }\n","#     g_update = xp.multiply(fidelity / mu, input_image)\n","#     for i in tqdm(range(iter_num), total=iter_num):\n","#         #print(f\"Starting iteration {i+1}\")\n","#         g_update = xp.fft.fftn(g_update)\n","#         if i == 0:\n","#             g = xp.fft.ifftn(g_update / (fidelity / mu)).real\n","#         else:\n","#             g = xp.fft.ifftn(xp.divide(g_update, norm_array)).real\n","#         g_update = xp.multiply((fidelity / mu), input_image)\n","        \n","#         #print(\"XX update\")\n","#         L, b_arrays[\"xx\"] = iter_xx(g, b_arrays[\"xx\"], continuity_scale, mu)\n","#         g_update += L\n","        \n","#         #print(\"YY update\")\n","#         L, b_arrays[\"yy\"] = iter_yy(g, b_arrays[\"yy\"], continuity_scale, mu)\n","#         g_update += L\n","        \n","#         #print(\"XY update\")\n","#         L, b_arrays[\"xy\"] = iter_xy(g, b_arrays[\"xy\"], 2 * continuity_scale, mu)\n","#         g_update += L\n","        \n","#         #print(\"L1 update\")\n","#         L, b_arrays[\"L1\"] = iter_sparse(g, b_arrays[\"L1\"], sparsity_scale, mu)\n","#         g_update += L\n","        \n","#     g_update = xp.fft.fftn(g_update)\n","#     g = xp.fft.ifftn(xp.divide(g_update, norm_array)).real\n","    \n","#     g[g < 0] = 0\n","#     g -= g.min()\n","#     g /= g.max()\n","#     return g"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## dataset"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T05:05:37.961199Z","iopub.status.busy":"2023-05-18T05:05:37.96084Z","iopub.status.idle":"2023-05-18T05:05:37.969555Z","shell.execute_reply":"2023-05-18T05:05:37.96832Z","shell.execute_reply.started":"2023-05-18T05:05:37.961169Z"},"trusted":true},"outputs":[],"source":["def read_image(mode, fragment_id):\n","    images = []\n","\n","    # idxs = range(65)\n","    mid = 65 // 2\n","    start = mid - CFG.in_chans // 2\n","    end = mid + CFG.in_chans // 2\n","    idxs = range(start, end)\n","\n","    for i in tqdm(idxs):\n","        image = cv2.imread(CFG.comp_dataset_path + f\"{mode}/{fragment_id}/surface_volume/{i:02}.tif\", -1)\n","\n","        pad0 = (CFG.prd_size - image.shape[0] % CFG.prd_size)\n","        pad1 = (CFG.prd_size - image.shape[1] % CFG.prd_size)\n","\n","        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n","\n","        images.append(image)\n","    images = np.stack(images, axis=2)\n","    \n","    return images"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T05:05:37.972599Z","iopub.status.busy":"2023-05-18T05:05:37.972104Z","iopub.status.idle":"2023-05-18T05:05:37.982419Z","shell.execute_reply":"2023-05-18T05:05:37.981368Z","shell.execute_reply.started":"2023-05-18T05:05:37.972562Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, images, cfg,xys, labels=None):\n","        self.images = images\n","        self.cfg = cfg\n","        self.labels = labels\n","        self.xys=xys\n","\n","    def __len__(self):\n","        # return len(self.xyxys)\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        # x1, y1, x2, y2 = self.xyxys[idx]\n","        image = self.images[idx]\n","        image=tc.from_numpy(image).permute(2,0,1).to(tc.float32)/255\n","        image = (image - 0.45)/0.225\n","        return image,self.xys[idx]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import OneHotEncoder\n","\n","from albumentations.core.transforms_interface import ImageOnlyTransform\n","\n","class NormalizeTransform(ImageOnlyTransform):\n","    def __init__(self, always_apply=False, p=1.0):\n","        super(NormalizeTransform, self).__init__(always_apply, p)\n","\n","    def apply(self, img, **params):\n","        median = np.full_like(img, all_median).astype(np.float32)\n","        mad = np.full_like(img, all_MAD).astype(np.float32)\n","        # img = (img - median) / mad\n","        img = img / median\n","        # img[img < 0] = 0\n","        return img\n","\n","\n","class SubvolumeDataset(Dataset):\n","    def __init__(self, locations, volume, labels, buffer, is_train: bool, return_location: bool = False):\n","        self.locations = locations\n","        self.volume = volume\n","        self.labels = labels        \n","        self.buffer = buffer\n","        self.is_train = is_train\n","        self.return_location = return_location\n","\n","    def __len__(self):\n","        return len(self.locations)\n","\n","    def __getitem__(self, idx):\n","        global possible_min_input, possible_max_input\n","        label = None\n","        location = np.array(self.locations[idx])\n","        y, x = location[0], location[1]\n","\n","        subvolume = extract_subvolume(location, self.volume)\n","        # print(\"subvolume\", subvolume)\n","        # print(\"labels\", labels)\n","        # subvolume = subvolume.numpy()\n","        subvolume = subvolume\n","        \n","        if self.labels is not None:\n","            label = self.labels[y - self.buffer:y + self.buffer, x - self.buffer:x + self.buffer]\n","            # print(\"label\", label)\n","            # n_category = 2\n","            # label = np.eye(n_category)[label]\n","            label = np.stack([label], axis=-1)\n","            # label = label.numpy()\n","            # print(\"label.shape\", label.shape\n","        \n","        if self.is_train and label is not None:            \n","            \n","            # print(\"label\", label.dtype)\n","            # print(\"subvolume in train dataset (before aug)\", subvolume, file=open(\"before-train-aug.log\", \"w\")) \n","            size = int(BUFFER * 2)\n","            performed = A.Compose([\n","                # A.ToFloat(max_value=possible_max_input - possible_min_input),\n","                # A.ToFloat(max_value=2**16-1),       \n","                NormalizeTransform(always_apply=True),         \n","                A.HorizontalFlip(p=0.5), # 水平方向に反転\n","                A.VerticalFlip(p=0.5), # 水平方向に反転\n","                A.RandomRotate90(p=0.5),\n","                # A.RandomBrightnessContrast(p=0.4),\n","                A.ShiftScaleRotate(p=0.5, border_mode=0), # シフト、スケーリング、回転\n","                # A.PadIfNeeded(min_height=size, min_width=size, always_apply=True, border_mode=0), # 必要に応じてパディングを追加\n","                A.RandomCrop(height=int(size / 1.25), width=int(size / 1.25), p=0.5), # ランダムにクロップ, Moduleの中で計算する際に次元がバッチ内で揃っている必要があるので最後にサイズは揃える\n","                # A.Perspective(p=0.5), # パースペクティブ変換                \n","                A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n","                A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3), \n","                                mask_fill_value=0, p=0.2),\n","                A.OneOf([\n","                    # A.GaussNoise(var_limit=[1, 1]), # NG\n","                    A.GaussianBlur(blur_limit=(3, 5)),\n","                    A.MotionBlur(blur_limit=5, p=1),\n","                ], p=1),\n","                A.Resize(BUFFER * 2, BUFFER * 2, always_apply=True),                \n","                # A.Normalize(\n","                #     mean= [0] * Z_DIM,\n","                #     std= [1] * Z_DIM\n","                # ),\n","                # A.FromFloat(max_value=possible_max_input - possible_min_input),                \n","                ToTensorV2(transpose_mask=True),                \n","            ])(image=subvolume, mask=label)            \n","            subvolume = performed[\"image\"]\n","            label = performed[\"mask\"]\n","            # print(\"subvolume in train dataset (after aug)\", subvolume, file=open(\"after-train-aug.log\", \"w\"))\n","            # print(\"label\", label.dtype)\n","            # print(\"subvolume\", subvolume.dtype)\n","            # →C, H, W\n","            # subvolume = torch.from_numpy(subvolume.transpose(2, 0, 1).astype(np.float32))\n","            # print(performed)\n","            # print(subvolume.shape, label.shape)\n","            # H, W, C → C, H, W\n","            # label = torch.from_numpy(label.transpose(2, 0, 1).astype(np.uint8)) \n","        else:\n","            if label is None:\n","                performed = A.Compose([            \n","                    # A.ToFloat(max_value=possible_max_input - possible_min_input),\n","                    # A.ToFloat(max_value=2**16-1),\n","                    # A.Normalize(\n","                    #     mean= [0] * Z_DIM,\n","                    #     std= [1] * Z_DIM\n","                    # ),\n","                    # A.FromFloat(max_value=possible_max_input - possible_min_input),\n","                    NormalizeTransform(always_apply=True),\n","                    ToTensorV2(transpose_mask=True),\n","                ])(image=subvolume)\n","                subvolume = performed[\"image\"]\n","            else:\n","                # print(\"subvolume in val dataset (before aug)\", subvolume, file=open(\"before-val-aug.log\", \"w\")) \n","                performed = A.Compose([            \n","                    # A.ToFloat(max_value=possible_max_input - possible_min_input),\n","                    # A.ToFloat(max_value=2**16-1),\n","                    # A.Normalize(\n","                    #     mean= [0] * Z_DIM,\n","                    #     std= [1] * Z_DIM\n","                    # ),\n","                    # A.FromFloat(max_value=possible_max_input - possible_min_input),\n","                    NormalizeTransform(always_apply=True),\n","                    ToTensorV2(transpose_mask=True),\n","                ])(image=subvolume, mask=label)                \n","                label = performed[\"mask\"]                \n","                subvolume = performed[\"image\"]\n","                # print(\"subvolume in val dataset (after aug)\", subvolume, file=open(\"after-val-aug.log\", \"w\"))                \n","            # subvolume = torch.from_numpy(subvolume.transpose(2, 0, 1).astype(np.float32))\n","            # if label is not None:\n","                # label = torch.from_numpy(label.transpose(2, 0, 1).astype(np.uint8)) \n","        if self.return_location:\n","            return subvolume, location\n","        return subvolume, label        "]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T05:05:37.984974Z","iopub.status.busy":"2023-05-18T05:05:37.983869Z","iopub.status.idle":"2023-05-18T05:05:37.996389Z","shell.execute_reply":"2023-05-18T05:05:37.995129Z","shell.execute_reply.started":"2023-05-18T05:05:37.984894Z"},"trusted":true},"outputs":[],"source":["def make_train_dataset(fragment_id):\n","    images = read_image(CFG.mode, fragment_id)\n","    \n","    x1_list = list(range(0, images.shape[1]-CFG.prd_size+1, CFG.stride))\n","    y1_list = list(range(0, images.shape[0]-CFG.prd_size+1, CFG.stride))\n","    \n","    images_list = []\n","    xyxys = []\n","    for y1 in y1_list:\n","        for x1 in x1_list:\n","            y2 = y1 + CFG.prd_size\n","            x2 = x1 + CFG.prd_size\n","            if np.all(images[y1:y2, x1:x2]==0):\n","                continue\n","            images_list.append(images[y1:y2, x1:x2])\n","            xyxys.append((x1, y1, x2, y2))\n","    xyxys = np.stack(xyxys)\n","\n","    ds = CustomDataset(images_list, CFG,xys=xyxys)\n","    \n","    loader = DataLoader(\n","        ds,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","    \n","    return loader, xyxys"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3D ResNet"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T05:05:37.99883Z","iopub.status.busy":"2023-05-18T05:05:37.998208Z","iopub.status.idle":"2023-05-18T05:05:38.197442Z","shell.execute_reply":"2023-05-18T05:05:38.196189Z","shell.execute_reply.started":"2023-05-18T05:05:37.998793Z"},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, encoder_dims, upscale):\n","        super().__init__()\n","        self.convs = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv2d(encoder_dims[i]+encoder_dims[i-1], encoder_dims[i-1], 3, 1, 1, bias=False),\n","                nn.BatchNorm2d(encoder_dims[i-1]),\n","                nn.ReLU(inplace=True)\n","            ) for i in range(1, len(encoder_dims))])\n","\n","        self.logit = nn.Conv2d(encoder_dims[0], 1, 1, 1, 0)\n","        self.up = nn.Upsample(scale_factor=upscale, mode=\"bilinear\")\n","\n","    def forward(self, feature_maps):\n","        for i in range(len(feature_maps)-1, 0, -1):\n","            f_up = F.interpolate(feature_maps[i], scale_factor=2, mode=\"bilinear\")\n","            f = torch.cat([feature_maps[i-1], f_up], dim=1)\n","            f_down = self.convs[i-1](f)\n","            feature_maps[i-1] = f_down\n","\n","        x = self.logit(feature_maps[0])\n","        mask = self.up(x)\n","        return mask\n","    \n","class SegModel(nn.Module):\n","    def __init__(self,model_depth=34):\n","        super().__init__()\n","        self.encoder = generate_model(model_depth=model_depth, n_input_channels=1)\n","        self.decoder = Decoder(encoder_dims=[64, 128, 256, 512], upscale=4)\n","        \n","    def forward(self, x):\n","        if x.ndim==4:\n","            x=x[:,None]\n","        \n","        feat_maps = self.encoder(x)\n","        feat_maps_pooled = [torch.mean(f, dim=2) for f in feat_maps]\n","        pred_mask = self.decoder(feat_maps_pooled)\n","        return pred_mask\n","        \n","class CustomModel(nn.Module):\n","    def __init__(self, cfg=CFG, weight=None):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if cfg.backbone==\"resnet3d\":\n","            self.encoder=SegModel()\n","        elif cfg.backbone[:3]!=\"mit\":\n","            self.encoder = smp.Unet(\n","                encoder_name=cfg.backbone, \n","                encoder_weights=weight,\n","                in_channels=cfg.in_chans,\n","                classes=cfg.target_size,\n","                activation=None,\n","            )\n","        else :\n","            self.encoder = smp.Unet(\n","                encoder_name=cfg.backbone, \n","                encoder_weights=weight,\n","                classes=cfg.target_size,\n","                activation=None,\n","            )\n","            print(\"self.encoder.encoder.patch_embed1.proj\", self.encoder.encoder.patch_embed1.proj)\n","            out_channels=self.encoder.encoder.patch_embed1.proj.out_channels\n","            self.encoder.encoder.patch_embed1.proj=nn.Conv2d(cfg.in_chans,out_channels,7,4,3)\n","\n","    def forward(self, images:torch.Tensor):\n","        #image.shape=(b,C,H,W)\n","        if images.ndim==4:\n","            images=images[:,None]\n","        images=normalization(images)\n","        output = self.encoder(images)\n","        return output\n","\n","def build_model(cfg, weight=\"imagenet\"):\n","    print('model_name', cfg.model_name)\n","    print('backbone', cfg.backbone)\n","\n","    model = CustomModel(cfg, weight)\n","    return model\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T05:05:38.202161Z","iopub.status.busy":"2023-05-18T05:05:38.20123Z","iopub.status.idle":"2023-05-18T05:05:38.213584Z","shell.execute_reply":"2023-05-18T05:05:38.212513Z","shell.execute_reply.started":"2023-05-18T05:05:38.202121Z"},"trusted":true},"outputs":[],"source":["def TTA(x:tc.Tensor,model:nn.Module):\n","    #x.shape=(batch,c,h,w)\n","    shape=x.shape\n","    x=[x,*[tc.rot90(x,k=i,dims=(-2,-1)) for i in range(1,4)]]\n","    x=tc.cat(x,dim=0)\n","    x=model(x)\n","    x=torch.sigmoid(x)\n","    x=x.reshape(4,shape[0],*shape[2:])\n","    x=[tc.rot90(x[i],k=-i,dims=(-2,-1)) for i in range(4)]\n","    x=tc.stack(x,dim=0)\n","    return x.mean(0)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T05:05:38.216573Z","iopub.status.busy":"2023-05-18T05:05:38.215837Z","iopub.status.idle":"2023-05-18T05:05:42.03788Z","shell.execute_reply":"2023-05-18T05:05:42.036598Z","shell.execute_reply.started":"2023-05-18T05:05:38.216529Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model_name Unet\n","backbone resnet3d\n"]},{"data":{"text/plain":["True"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["#in_submission=get_folder_size(\"/kaggle/input/vesuvius-challenge-ink-detection/test\")!=6732244267\n","in_submission=False\n","IS_DEBUG = False\n","mode = 'train' if IS_DEBUG else 'test'\n","TH = 0.55\n","fragment_ids = [1, 2]\n","\n","model = build_model(CFG)\n","# model.load_state_dict(tc.load(\"/kaggle/input/3d-resnet-baseline-inference-model-data/resnet3d-34_3d_seg_epoch_14.pth\"))\n","model = nn.DataParallel(model, device_ids=[0, 1, 2])\n","model = model.cuda()#.eval()\n","model.training"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## main"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T05:05:42.041465Z","iopub.status.busy":"2023-05-18T05:05:42.040711Z","iopub.status.idle":"2023-05-18T05:06:06.128361Z","shell.execute_reply":"2023-05-18T05:06:06.126683Z","shell.execute_reply.started":"2023-05-18T05:05:42.041423Z"},"trusted":true},"outputs":[],"source":["results = []\n","\n","def train(fragment_id):\n","    loader, xyxys = make_train_dataset(fragment_id)\n","    binary_mask = cv2.imread(CFG.comp_dataset_path + f\"{mode}/{fragment_id}/mask.png\", 0)\n","    binary_mask = (binary_mask / 255).astype(int)\n","    \n","    ori_h = binary_mask.shape[0]\n","    ori_w = binary_mask.shape[1]\n","\n","    pad0 = (CFG.prd_size - binary_mask.shape[0] % CFG.prd_size)\n","    pad1 = (CFG.prd_size - binary_mask.shape[1] % CFG.prd_size)\n","\n","    binary_mask = np.pad(binary_mask, [(0, pad0), (0, pad1)], constant_values=0)\n","    \n","    for step, (images, xys) in tqdm(enumerate(loader), total=len(loader)):\n","        images: torch.Tensor = images\n","        images = images.cuda()\n","        batch_size = images.size(0)\n","        \n","        preds = model(images)\n","    \n","\n","for fragment_id in fragment_ids:\n","    if in_submission:\n","        break\n","    test_loader, xyxys = make_train_dataset(fragment_id)\n","    \n","    binary_mask = cv2.imread(CFG.comp_dataset_path + f\"{mode}/{fragment_id}/mask.png\", 0)\n","    binary_mask = (binary_mask / 255).astype(int)\n","    \n","    ori_h = binary_mask.shape[0]\n","    ori_w = binary_mask.shape[1]\n","\n","    pad0 = (CFG.prd_size - binary_mask.shape[0] % CFG.prd_size)\n","    pad1 = (CFG.prd_size - binary_mask.shape[1] % CFG.prd_size)\n","\n","    binary_mask = np.pad(binary_mask, [(0, pad0), (0, pad1)], constant_values=0)\n","\n","    mask_pred = np.zeros(binary_mask.shape)\n","    mask_count = np.zeros(binary_mask.shape)\n","    for step, (images,xys) in tqdm(enumerate(test_loader), total=len(test_loader)):\n","        images = images.cuda()\n","        batch_size = images.size(0)\n","\n","        with torch.no_grad():\n","            y_preds=TTA(images,model)\n","            \n","        \n","        for k, (x1, y1, x2, y2) in enumerate(xys):\n","            mask_pred[y1:y2, x1:x2] += y_preds[k].squeeze(0).cpu().numpy()\n","            mask_count[y1:y2, x1:x2] += 1\n","        \n","    print(f'mask_count_min: {mask_count.min()}')\n","    mask_pred /= (mask_count+1e-7)\n","\n","    \n","    fig, axes = plt.subplots(1, 4, figsize=(15, 8))\n","    axes[0].imshow(mask_count)\n","    axes[1].imshow(mask_pred.copy())\n","    \n","    axes[2].imshow(mask_pred)\n","    \n","    mask_pred = mask_pred[:ori_h, :ori_w]\n","    binary_mask = binary_mask[:ori_h, :ori_w]\n","    \n","    mask_pred = (mask_pred >= TH).astype(np.uint8)\n","    mask_pred=mask_pred.astype(int)\n","    mask_pred *= binary_mask\n","    \n","    axes[3].imshow(mask_pred)\n","    plt.show()\n","    \n","    inklabels_rle = rle(mask_pred)\n","    \n","    results.append((fragment_id, inklabels_rle))\n","    \n","\n","    del mask_pred, mask_count\n","    del test_loader\n","    \n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    plt.clf()\n","    fig.clear()\n","    plt.close(fig)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T05:06:08.40128Z","iopub.status.busy":"2023-05-18T05:06:08.4008Z","iopub.status.idle":"2023-05-18T05:06:09.64892Z","shell.execute_reply":"2023-05-18T05:06:09.647393Z","shell.execute_reply.started":"2023-05-18T05:06:08.401245Z"},"trusted":true},"outputs":[],"source":["! cp /kaggle/input/vesuvius-challenge-ink-detection/sample_submission.csv submission.csv\n","if in_submission:\n","    sub = pd.DataFrame(results, columns=['Id', 'Predicted'])\n","    #sub\n","    sample_sub = pd.read_csv(CFG.comp_dataset_path + 'sample_submission.csv')\n","    sample_sub = pd.merge(sample_sub[['Id']], sub, on='Id', how='left')\n","    #sample_sub\n","    sample_sub.to_csv(\"submission.csv\", index=False)\n","    print(\"ok\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":4}
